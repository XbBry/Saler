# Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù†Ø´Ø± - Development Deployment Guide

## Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

ÙŠÙˆØ¶Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø·Ø±Ù‚ Ù†Ø´Ø± ØªØ·Ø¨ÙŠÙ‚ Saler ÙÙŠ Ø¨ÙŠØ¦Ø§Øª Ù…Ø®ØªÙ„ÙØ©ØŒ Ù…Ù† Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ù†ØªØ§Ø¬. Ø³Ù†ØºØ·ÙŠ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ù…Ø®ØªÙ„ÙØ©ØŒ ÙˆØ£Ø¯ÙˆØ§Øª CI/CDØŒ ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©.

## Ù…Ø­ØªÙˆÙŠØ§Øª Ø§Ù„Ø¯Ù„ÙŠÙ„

1. [Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø´Ø±](#Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª-Ø§Ù„Ù†Ø´Ø±)
2. [Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ù…Ø­Ù„ÙŠ](#Ø§Ù„Ù†Ø´Ø±-Ø§Ù„Ù…Ø­Ù„ÙŠ)
3. [Docker Deployment](#docker-deployment)
4. [CI/CD Pipeline](#cicd-pipeline)
5. [Production Deployment](#production-deployment)
6. [Cloud Deployments](#cloud-deployments)
7. [Database Migration](#database-migration)
8. [Monitoring & Logging](#monitoring--logging)
9. [Security Considerations](#security-considerations)
10. [Rollback Strategies](#rollback-strategies)

## Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø´Ø±

### Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…

```yaml
# Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…
- Ubuntu 20.04+ LTS
- CentOS 8+
- macOS 12+
- Windows 10+ (WSL2)

# Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©
- CPU: 4+ cores
- RAM: 8GB+ minimum, 16GB+ recommended
- Storage: 50GB+ SSD
- Network: 100Mbps+ connection

# Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
- Node.js 18+
- Python 3.11+
- Docker 24+
- Docker Compose 2+
- PostgreSQL 15+
- Redis 7+
```

### Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©

```bash
# Ù…Ù„Ù .env Ù„Ù„Ù†Ø´Ø±
NODE_ENV=production
API_URL=https://api.saler.app
FRONTEND_URL=https://saler.app
DATABASE_URL=postgresql://user:pass@localhost:5432/saler
REDIS_URL=redis://localhost:6379/0

# Ø£Ù…Ø§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
JWT_SECRET=your-super-secret-jwt-key
ENCRYPTION_KEY=your-encryption-key
BCRYPT_ROUNDS=12

# APIs Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©
SHOPIFY_API_KEY=your-shopify-key
SHOPIFY_API_SECRET=your-shopify-secret
META_API_KEY=your-meta-key
META_API_SECRET=your-meta-secret

# Ø§Ù„ØªØ®Ø²ÙŠÙ†
S3_BUCKET=saler-assets
S3_REGION=us-east-1
AWS_ACCESS_KEY_ID=your-aws-key
AWS_SECRET_ACCESS_KEY=your-aws-secret

# Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
SENTRY_DSN=your-sentry-dsn
LOG_LEVEL=info

# Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-email-password
```

## Ø§Ù„Ù†Ø´Ø± Ø§Ù„Ù…Ø­Ù„ÙŠ

### Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©

```bash
#!/bin/bash
# setup-local.sh - Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ©

echo "ğŸš€ Ø¨Ø¯Ø¡ Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø­Ù„ÙŠØ©..."

# ØªØ«Ø¨ÙŠØª Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª
echo "ğŸ“¦ ØªØ«Ø¨ÙŠØª ØªØ¨Ø¹ÙŠØ§Øª Node.js..."
npm install

echo "ğŸ“¦ ØªØ«Ø¨ÙŠØª ØªØ¨Ø¹ÙŠØ§Øª Python..."
pip install -r requirements.txt

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
echo "ğŸ—„ï¸ Ø¥Ø¹Ø¯Ø§Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."
python manage.py db upgrade

# ØªØ«Ø¨ÙŠØª Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
echo "ğŸ”§ ØªØ«Ø¨ÙŠØª Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ·ÙˆÙŠØ±..."
npm install -g concurrently nodemon

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
echo "âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©..."
cp .env.example .env

echo "âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ù…Ø­Ù„ÙŠØ© Ø¨Ù†Ø¬Ø§Ø­!"
```

### ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø­Ù„ÙŠØ§Ù‹

```bash
#!/bin/bash
# run-local.sh - ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø­Ù„ÙŠØ§Ù‹

echo "ğŸ”„ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙŠ ÙˆØ¶Ø¹ Ø§Ù„ØªØ·ÙˆÙŠØ±..."

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
docker-compose up -d postgres redis

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ù„ÙÙŠØ©
npm run server

# ØªØ´ØºÙŠÙ„ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ©
npm run client

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… ÙƒÙƒÙ„
npm run dev
```

## Docker Deployment

### Dockerfile Ù„Ù„ØªØ·Ø¨ÙŠÙ‚

```dockerfile
# Dockerfile
FROM node:18-alpine AS builder

WORKDIR /app

# Ù†Ø³Ø® Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª
COPY package*.json ./
RUN npm ci --only=production

# Ù†Ø³Ø® Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØµØ¯Ø±
COPY . .

# Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
RUN npm run build

# Ù…Ø±Ø­Ù„Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
FROM node:18-alpine

WORKDIR /app

# ØªØ«Ø¨ÙŠØª Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
RUN apk add --no-cache \
    python3 \
    py3-pip \
    make \
    g++

# Ù†Ø³Ø® Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
COPY --from=builder /app ./

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ±-root
RUN addgroup -g 1001 -S nodejs
RUN adduser -S saler -u 1001

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
RUN chown -R saler:nodejs /app
USER saler

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù†ÙØ°
EXPOSE 3000

# ÙØ­Øµ ØµØ­Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3000/health || exit 1

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
CMD ["node", "dist/server.js"]
```

### Docker Compose Ù„Ù„Ù†Ø´Ø±

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://postgres:password@postgres:5432/saler
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis
    volumes:
      - ./logs:/app/logs
      - ./uploads:/app/uploads
    restart: unless-stopped
    networks:
      - saler-network

  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=saler
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backups:/backups
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - saler-network

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped
    networks:
      - saler-network

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/ssl/certs
      - ./uploads:/var/www/uploads
    depends_on:
      - app
    restart: unless-stopped
    networks:
      - saler-network

volumes:
  postgres_data:
  redis_data:

networks:
  saler-network:
    driver: bridge
```

### Docker Compose Ù„Ù„Ø¥Ù†ØªØ§Ø¬

```yaml
# docker-compose.prod.yml
version: '3.8'

services:
  app:
    build: 
      context: .
      dockerfile: Dockerfile
    deploy:
      replicas: 3
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      update_config:
        parallelism: 1
        delay: 10s
        failure_action: rollback
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  postgres:
    image: postgres:15-alpine
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M
    command: |
      postgres
        -c max_connections=200
        -c shared_buffers=256MB
        -c effective_cache_size=1GB
        -c maintenance_work_mem=64MB
        -c checkpoint_completion_target=0.9
        -c wal_buffers=16MB
        -c default_statistics_target=100

  redis:
    image: redis:7-alpine
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.prod.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/ssl/certs
    deploy:
      resources:
        limits:
          memory: 128M
```

## CI/CD Pipeline

### GitHub Actions

```yaml
# .github/workflows/deploy.yml
name: Deploy to Production

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run tests
        run: |
          npm run test:unit
          npm run test:integration
          npm run test:e2e

      - name: Run security audit
        run: npm audit --audit-level moderate

  build:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy-staging:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: staging
    
    steps:
      - name: Deploy to staging
        run: |
          echo "ğŸš€ Ù†Ø´Ø± Ø¹Ù„Ù‰ Ø¨ÙŠØ¦Ø© Staging..."
          # Commands to deploy to staging environment

  deploy-production:
    needs: build
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
      - name: Deploy to production
        run: |
          echo "ğŸš€ Ù†Ø´Ø± Ø¹Ù„Ù‰ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬..."
          # Commands to deploy to production environment

      - name: Run smoke tests
        run: |
          echo "ğŸ§ª ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø¥Ø­Ù…Ø§Ø¡..."
          # Commands to run smoke tests after deployment
```

### GitLab CI/CD

```yaml
# .gitlab-ci.yml
stages:
  - test
  - build
  - staging
  - production

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: "/certs"

services:
  - name: docker:24-dind
    command: ["--mtu=1460"]

test:
  stage: test
  image: node:18-alpine
  before_script:
    - npm ci
  script:
    - npm run test
    - npm run lint
    - npm audit

build:
  stage: build
  image: docker:24
  services:
    - docker:24-dind
  script:
    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .
    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA
  only:
    - main

deploy-staging:
  stage: staging
  image: alpine:latest
  before_script:
    - apk add --no-cache openssh-client
    - eval $(ssh-agent -s)
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
  script:
    - ssh -o StrictHostKeyChecking=no $STAGING_USER@$STAGING_HOST "cd /var/www/saler && docker-compose pull && docker-compose up -d"
  environment:
    name: staging
    url: https://staging.saler.app
  only:
    - main

deploy-production:
  stage: production
  image: alpine:latest
  before_script:
    - apk add --no-cache openssh-client
    - eval $(ssh-agent -s)
    - echo "$SSH_PRIVATE_KEY" | tr -d '\r' | ssh-add -
    - mkdir -p ~/.ssh
    - chmod 700 ~/.ssh
  script:
    - ssh -o StrictHostKeyChecking=no $PROD_USER@$PROD_HOST "cd /var/www/saler && docker-compose pull && docker-compose up -d"
  environment:
    name: production
    url: https://saler.app
  when: manual
  only:
    - main
```

### Jenkins Pipeline

```groovy
// Jenkinsfile
pipeline {
    agent any
    
    environment {
        DOCKER_REGISTRY = 'registry.saler.app'
        IMAGE_NAME = 'saler-app'
        BUILD_NUMBER = env.BUILD_NUMBER ?: '0'
    }
    
    stages {
        stage('Checkout') {
            steps {
                checkout scm
            }
        }
        
        stage('Test') {
            parallel {
                stage('Unit Tests') {
                    steps {
                        sh 'npm test'
                    }
                }
                
                stage('Integration Tests') {
                    steps {
                        sh 'npm run test:integration'
                    }
                }
                
                stage('Security Scan') {
                    steps {
                        sh 'npm audit'
                        sh 'snyk test'
                    }
                }
            }
        }
        
        stage('Build') {
            steps {
                script {
                    docker.build("${IMAGE_NAME}:${BUILD_NUMBER}")
                }
            }
        }
        
        stage('Push to Registry') {
            steps {
                script {
                    docker.withRegistry("https://${DOCKER_REGISTRY}", 'docker-registry-credentials') {
                        docker.image("${IMAGE_NAME}:${BUILD_NUMBER}").push()
                        docker.image("${IMAGE_NAME}:${BUILD_NUMBER}").push('latest')
                    }
                }
            }
        }
        
        stage('Deploy Staging') {
            when {
                branch 'develop'
            }
            steps {
                sh """
                    ssh staging-server "
                        cd /var/www/saler
                        docker-compose pull
                        docker-compose up -d
                    "
                """
            }
        }
        
        stage('Deploy Production') {
            when {
                branch 'main'
            }
            steps {
                sh """
                    ssh production-server "
                        cd /var/www/saler
                        docker-compose pull
                        docker-compose up -d
                        docker system prune -f
                    "
                """
            }
        }
    }
    
    post {
        always {
            archiveArtifacts artifacts: 'logs/**/*', fingerprint: true
            publishHTML([
                allowMissing: false,
                alwaysLinkToLastBuild: true,
                keepAll: true,
                reportDir: 'coverage',
                reportFiles: 'index.html',
                reportName: 'Coverage Report'
            ])
        }
        
        success {
            sh 'echo "Deployment successful!"'
        }
        
        failure {
            sh 'echo "Deployment failed!"'
            mail to: 'devops@saler.app',
                 subject: 'Deployment Failed',
                 body: "The deployment for build ${BUILD_NUMBER} failed."
        }
    }
}
```

## Production Deployment

### Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø®Ø§Ø¯Ù…

```bash
#!/bin/bash
# setup-production.sh - Ø¥Ø¹Ø¯Ø§Ø¯ Ø®Ø§Ø¯Ù… Ø§Ù„Ø¥Ù†ØªØ§Ø¬

echo "ğŸš€ Ø¥Ø¹Ø¯Ø§Ø¯ Ø®Ø§Ø¯Ù… Ø§Ù„Ø¥Ù†ØªØ§Ø¬..."

# ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ø¸Ø§Ù…
sudo apt update && sudo apt upgrade -y

# ØªØ«Ø¨ÙŠØª Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh

# ØªØ«Ø¨ÙŠØª Docker Compose
sudo curl -L "https://github.com/docker/compose/releases/download/v2.20.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
sudo adduser saler
sudo usermod -aG docker saler

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
sudo mkdir -p /var/www/saler
sudo chown saler:saler /var/www/saler

# Ø¥Ø¹Ø¯Ø§Ø¯ Nginx
sudo apt install nginx -y
sudo systemctl enable nginx

# Ø¥Ø¹Ø¯Ø§Ø¯ SSL Ù…Ø¹ Let's Encrypt
sudo apt install certbot python3-certbot-nginx -y

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¬Ø¯Ø§Ø± Ø§Ù„Ù†Ø§Ø±ÙŠ
sudo ufw allow 22/tcp
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw enable

echo "âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø®Ø§Ø¯Ù… Ø¨Ù†Ø¬Ø§Ø­!"
```

### Ù†Ø´Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚

```bash
#!/bin/bash
# deploy-production.sh - Ù†Ø´Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬

echo "ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø´Ø± ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬..."

# ØªØ­Ø¯ÙŠØ« Ø§Ù„ÙƒÙˆØ¯
cd /var/www/saler
git pull origin main

# Ø¨Ù†Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
docker-compose build --no-cache

# ØªØ´ØºÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª
docker-compose up -d postgres redis

# Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
echo "â³ Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."
sleep 30

# ØªØ´ØºÙŠÙ„ migrations
docker-compose exec app npm run db:migrate

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
docker-compose up -d app nginx

# ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª
docker-compose ps

# Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
docker-compose restart app

echo "âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø± Ø¨Ù†Ø¬Ø§Ø­!"
```

### Ø¥Ø¹Ø¯Ø§Ø¯ Nginx

```nginx
# nginx.prod.conf
user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    client_max_body_size 100M;

    # Ø¶ØºØ· Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    gzip on;
    gzip_vary on;
    gzip_min_length 10240;
    gzip_proxied expired no-cache no-store private must-revalidate;
    gzip_types
        text/plain
        text/css
        text/xml
        text/javascript
        application/javascript
        application/xml+rss
        application/json;

    # Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=5r/m;

    upstream app_backend {
        server app:3000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    # Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆØ¬ÙŠÙ‡ HTTP Ø¥Ù„Ù‰ HTTPS
    server {
        listen 80;
        server_name saler.app www.saler.app;
        return 301 https://$server_name$request_uri;
    }

    # Ø§Ù„Ø®Ø§Ø¯Ù… Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    server {
        listen 443 ssl http2;
        server_name saler.app www.saler.app;

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª SSL
        ssl_certificate /etc/ssl/certs/saler.crt;
        ssl_certificate_key /etc/ssl/private/saler.key;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512:ECDHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384;
        ssl_prefer_server_ciphers off;
        ssl_session_cache shared:SSL:10m;
        ssl_session_timeout 10m;

        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†
        add_header X-Frame-Options "SAMEORIGIN" always;
        add_header X-Content-Type-Options "nosniff" always;
        add_header X-XSS-Protection "1; mode=block" always;
        add_header Referrer-Policy "strict-origin-when-cross-origin" always;
        add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self'; connect-src 'self' wss: https:;" always;

        # Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¬Ø°Ø±
        root /var/www/html;
        index index.html;

        # Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©
        location /static/ {
            alias /var/www/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
            gzip_static on;
        }

        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
        location /uploads/ {
            alias /var/www/uploads/;
            expires 1y;
            add_header Cache-Control "public";
        }

        # API Routes
        location /api/ {
            limit_req zone=api burst=20 nodelay;
            
            proxy_pass http://app_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            
            # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù‡Ù„Ø©
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;
            proxy_read_timeout 60s;
        }

        # Authentication endpoints
        location /api/auth/ {
            limit_req zone=login burst=5 nodelay;
            
            proxy_pass http://app_backend;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # Socket.IO
        location /socket.io/ {
            proxy_pass http://app_backend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
        }

        # SPA fallback
        location / {
            try_files $uri $uri/ /index.html;
            
            # Cache Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©
            location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
                expires 1y;
                add_header Cache-Control "public, immutable";
                gzip_static on;
            }
        }

        # Health check
        location /health {
            access_log off;
            return 200 "healthy\n";
            add_header Content-Type text/plain;
        }

        # Logging
        access_log /var/log/nginx/access.log combined;
        error_log /var/log/nginx/error.log warn;
    }
}
```

## Cloud Deployments

### AWS ECS Deployment

```yaml
# ecs-task-definition.json
{
  "family": "saler-app",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "executionRoleArn": "arn:aws:iam::123456789012:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::123456789012:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "app",
      "image": "123456789012.dkr.ecr.us-east-1.amazonaws.com/saler-app:latest",
      "portMappings": [
        {
          "containerPort": 3000,
          "protocol": "tcp"
        }
      ],
      "essential": true,
      "environment": [
        {
          "name": "NODE_ENV",
          "value": "production"
        },
        {
          "name": "DATABASE_URL",
          "value": "postgresql://user:pass@rds-endpoint:5432/saler"
        }
      ],
      "secrets": [
        {
          "name": "JWT_SECRET",
          "valueFrom": "arn:aws:secretsmanager:us-east-1:123456789012:secret:saler/jwt-secret"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/saler-app",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:3000/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3,
        "startPeriod": 60
      }
    }
  ]
}
```

### Kubernetes Deployment

```yaml
# k8s-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: saler-app
  namespace: saler
  labels:
    app: saler-app
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: saler-app
  template:
    metadata:
      labels:
        app: saler-app
    spec:
      containers:
      - name: app
        image: saler-app:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: database-url
        - name: JWT_SECRET
          valueFrom:
            secretKeyRef:
              name: app-secrets
              key: jwt-secret
        resources:
          requests:
            memory: "256Mi"
            cpu: "250m"
          limits:
            memory: "512Mi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 60
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: uploads
          mountPath: /app/uploads
      volumes:
      - name: uploads
        persistentVolumeClaim:
          claimName: uploads-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: saler-app-service
  namespace: saler
spec:
  selector:
    app: saler-app
  ports:
  - port: 80
    targetPort: 3000
  type: ClusterIP
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: saler-app-ingress
  namespace: saler
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "100m"
spec:
  tls:
  - hosts:
    - saler.app
    - www.saler.app
    secretName: saler-tls
  rules:
  - host: saler.app
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: saler-app-service
            port:
              number: 80
```

### Heroku Deployment

```json
# package.json (Ø¥Ø¶Ø§ÙØ© scripts Ù„Ù„Ù†Ø´Ø±)
{
  "scripts": {
    "start": "node dist/server.js",
    "heroku-postbuild": "npm run build",
    "deploy": "git push heroku main"
  },
  "engines": {
    "node": "18.x"
  }
}
```

```bash
# heroku-deploy.sh
#!/bin/bash

echo "ğŸš€ Ù†Ø´Ø± Ø¹Ù„Ù‰ Heroku..."

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
heroku create saler-app --region eu

# Ø¥Ø¶Ø§ÙØ© Ø¥Ø¶Ø§ÙØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
heroku addons:create heroku-postgresql:mini -a saler-app
heroku addons:create heroku-redis:mini -a saler-app

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©
heroku config:set NODE_ENV=production -a saler-app
heroku config:set JWT_SECRET=your-jwt-secret -a saler-app

# Ù†Ø´Ø± Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
git push heroku main

# ØªØ´ØºÙŠÙ„ migrations
heroku run npm run db:migrate -a saler-app

# ÙØªØ­ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
heroku open -a saler-app

echo "âœ… ØªÙ… Ø§Ù„Ù†Ø´Ø± Ø¹Ù„Ù‰ Heroku Ø¨Ù†Ø¬Ø§Ø­!"
```

## Database Migration

### Alembic Migration

```python
# migrations/001_initial_schema.py
"""Initial database schema

Revision ID: 001
Revises: 
Create Date: 2024-01-01 12:00:00

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers
revision = '001'
down_revision = None
branch_labels = None
depends_on = None

def upgrade() -> None:
    # Create users table
    op.create_table('users',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('email', sa.String(255), nullable=False),
        sa.Column('password_hash', sa.String(255), nullable=False),
        sa.Column('first_name', sa.String(100), nullable=True),
        sa.Column('last_name', sa.String(100), nullable=True),
        sa.Column('is_active', sa.Boolean(), default=True),
        sa.Column('is_verified', sa.Boolean(), default=False),
        sa.Column('created_at', sa.DateTime(), server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), server_default=sa.func.now(), onupdate=sa.func.now()),
        sa.PrimaryKeyConstraint('id'),
        sa.Index('ix_users_email', 'email', unique=True)
    )

    # Create stores table
    op.create_table('stores',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(255), nullable=False),
        sa.Column('description', sa.Text(), nullable=True),
        sa.Column('owner_id', sa.Integer(), nullable=False),
        sa.Column('is_active', sa.Boolean(), default=True),
        sa.Column('settings', sa.JSON(), nullable=True),
        sa.Column('created_at', sa.DateTime(), server_default=sa.func.now()),
        sa.Column('updated_at', sa.DateTime(), server_default=sa.func.now(), onupdate=sa.func.now()),
        sa.PrimaryKeyConstraint('id'),
        sa.ForeignKeyConstraint(['owner_id'], ['users.id'], ),
        sa.Index('ix_stores_owner_id', 'owner_id')
    )

def downgrade() -> None:
    op.drop_table('stores')
    op.drop_table('users')
```

### Migration Scripts

```bash
#!/bin/bash
# run-migrations.sh - ØªØ´ØºÙŠÙ„ migrations

echo "ğŸ—„ï¸ ØªØ´ØºÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª migrations..."

# Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
echo "â³ Ø§Ù†ØªØ¸Ø§Ø± Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."
until docker-compose exec postgres pg_isready -U postgres; do
    sleep 1
done

# ØªØ´ØºÙŠÙ„ migrations
echo "âš™ï¸ ØªØ´ØºÙŠÙ„ migrations..."
docker-compose exec app npm run db:migrate

# ØªØ´ØºÙŠÙ„ seed data (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø·Ù„ÙˆØ¨Ø§Ù‹)
echo "ğŸŒ± ØªØ´ØºÙŠÙ„ seed data..."
docker-compose exec app npm run db:seed

echo "âœ… ØªÙ… ØªØ´ØºÙŠÙ„ migrations Ø¨Ù†Ø¬Ø§Ø­!"
```

```python
# scripts/migrate.py - Python migration script
import os
import subprocess
import sys
from datetime import datetime

def run_migration():
    """ØªØ´ØºÙŠÙ„ migrations Ù…Ø¹ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Ø¬Ø§Ø­"""
    
    try:
        print("ğŸ—„ï¸ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© migration...")
        
        # ØªØ´ØºÙŠÙ„ Alembic migrations
        result = subprocess.run([
            'alembic', 'upgrade', 'head'
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… ØªÙ… ØªØ´ØºÙŠÙ„ migrations Ø¨Ù†Ø¬Ø§Ø­!")
            
            # ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            verify_result = subprocess.run([
                'python', 'scripts/verify_db.py'
            ], capture_output=True, text=True)
            
            if verify_result.returncode == 0:
                print("âœ… ØªÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
            else:
                print("âš ï¸ ØªØ­Ø°ÙŠØ±: Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
                
        else:
            print("âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ´ØºÙŠÙ„ migrations:")
            print(result.stderr)
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ migration: {e}")
        sys.exit(1)

if __name__ == "__main__":
    run_migration()
```

## Monitoring & Logging

### Ø¥Ø¹Ø¯Ø§Ø¯ Log Management

```python
# config/logging_config.py
import logging
import logging.handlers
import json
from datetime import datetime
from typing import Dict, Any

class JSONFormatter(logging.Formatter):
    """ØªÙ†Ø³ÙŠÙ‚ Ø³Ø¬Ù„Ø§Øª JSON"""
    
    def format(self, record: logging.LogRecord) -> str:
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno,
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©
        if hasattr(record, 'request_id'):
            log_entry['request_id'] = record.request_id
            
        if hasattr(record, 'user_id'):
            log_entry['user_id'] = record.user_id
            
        if hasattr(record, 'ip_address'):
            log_entry['ip_address'] = record.ip_address
            
        return json.dumps(log_entry)

def setup_logging() -> None:
    """Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø³Ø¬Ù„Ø§Øª"""
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø³Ø¬Ù„ Ø§Ù„Ø¬Ø°Ø±
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    root_logger.handlers = []
    
    # Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù„Ù„ØªØ·Ø¨ÙŠÙ‚
    file_handler = logging.handlers.RotatingFileHandler(
        'logs/app.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setFormatter(JSONFormatter())
    file_handler.setLevel(logging.INFO)
    root_logger.addHandler(file_handler)
    
    # Ù…Ù„Ù Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
    error_handler = logging.handlers.RotatingFileHandler(
        'logs/error.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    error_handler.setFormatter(JSONFormatter())
    error_handler.setLevel(logging.ERROR)
    root_logger.addHandler(error_handler)
    
    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ù„Ù„Ø®Ø§Ø±Ø¬ (ELK Stack, Splunk, Ø¥Ù„Ø®)
    if os.getenv('LOG_AGGREGATION_URL'):
        setup_remote_logging()
    
    # Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬ Ù„Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©
    sensitive_handler = logging.handlers.RotatingFileHandler(
        'logs/audit.log',
        maxBytes=50*1024*1024,  # 50MB
        backupCount=10,
        encoding='utf-8'
    )
    sensitive_handler.setFormatter(JSONFormatter())
    sensitive_handler.setLevel(logging.INFO)
    
    # Ù…Ø³Ø¬Ù„ Ø®Ø§Øµ Ù„Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©
    audit_logger = logging.getLogger('audit')
    audit_logger.addHandler(sensitive_handler)
    audit_logger.setLevel(logging.INFO)
    audit_logger.propagate = False

def setup_remote_logging():
    """Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø¨Ø¹ÙŠØ¯Ø©"""
    import requests
    
    class RemoteHandler(logging.Handler):
        def emit(self, record):
            try:
                log_entry = self.format(record)
                requests.post(
                    os.getenv('LOG_AGGREGATION_URL'),
                    json={'message': log_entry},
                    timeout=5
                )
            except Exception:
                pass  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„
    
    remote_handler = RemoteHandler()
    remote_handler.setFormatter(JSONFormatter())
    
    root_logger = logging.getLogger()
    root_logger.addHandler(remote_handler)
```

### Health Check Endpoints

```python
# health.py - ÙØ­ÙˆØµØ§Øª ØµØ­Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
from flask import Blueprint, jsonify
import psycopg2
import redis
import requests
from datetime import datetime
import os

health_bp = Blueprint('health', __name__)

@health_bp.route('/health')
def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„ØªØ·Ø¨ÙŠÙ‚"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.utcnow().isoformat(),
        'version': os.getenv('APP_VERSION', 'unknown'),
        'environment': os.getenv('NODE_ENV', 'development')
    })

@health_bp.route('/ready')
def readiness_check():
    """ÙØ­Øµ Ø§Ø³ØªØ¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„ØªÙ„Ù‚ÙŠ Ø§Ù„Ø·Ù„Ø¨Ø§Øª"""
    checks = {
        'database': check_database(),
        'redis': check_redis(),
        'external_apis': check_external_apis()
    }
    
    all_healthy = all(checks.values())
    status_code = 200 if all_healthy else 503
    
    return jsonify({
        'status': 'ready' if all_healthy else 'not_ready',
        'checks': checks,
        'timestamp': datetime.utcnow().isoformat()
    }), status_code

@health_bp.route('/live')
def liveness_check():
    """ÙØ­Øµ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ¹Ù…Ù„"""
    return jsonify({
        'status': 'alive',
        'timestamp': datetime.utcnow().isoformat()
    })

def check_database() -> bool:
    """ÙØ­Øµ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    try:
        conn = psycopg2.connect(
            host=os.getenv('DB_HOST'),
            database=os.getenv('DB_NAME'),
            user=os.getenv('DB_USER'),
            password=os.getenv('DB_PASSWORD'),
            connect_timeout=5
        )
        cursor = conn.cursor()
        cursor.execute('SELECT 1')
        cursor.fetchone()
        conn.close()
        return True
    except Exception:
        return False

def check_redis() -> bool:
    """ÙØ­Øµ Ø§ØªØµØ§Ù„ Redis"""
    try:
        r = redis.Redis(
            host=os.getenv('REDIS_HOST'),
            port=int(os.getenv('REDIS_PORT', 6379)),
            decode_responses=True,
            socket_connect_timeout=5
        )
        r.ping()
        return True
    except Exception:
        return False

def check_external_apis() -> bool:
    """ÙØ­Øµ APIs Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©"""
    try:
        # ÙØ­Øµ API Ø®Ø§Ø±Ø¬Ø© Ù…Ø«Ø§Ù„ (Shopify, Meta Ads, Ø¥Ù„Ø®)
        response = requests.get(
            'https://api.external-service.com/health',
            timeout=5
        )
        return response.status_code == 200
    except Exception:
        return False
```

### Monitoring Scripts

```bash
#!/bin/bash
# monitor.sh - Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚

echo "ğŸ“Š Ø¨Ø¯Ø¡ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚..."

# Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
monitor_resources() {
    echo "ğŸ” Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø±Ø¯..."
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø©
    echo "CPU Usage: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | awk -F'%' '{print $1}')%"
    echo "Memory Usage: $(free | grep Mem | awk '{printf("%.1f"), $3/$2 * 100.0}')%"
    echo "Disk Usage: $(df -h / | awk 'NR==2{printf "%s", $5}')"
    
    # Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù†Ø´Ø·Ø©
    echo "Active Processes: $(ps aux | wc -l)"
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø´Ø¨ÙƒØ©
    echo "Network Connections: $(netstat -tuln | wc -l)"
}

# ÙØ­Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
check_database() {
    echo "ğŸ—„ï¸ ÙØ­Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."
    
    docker-compose exec -T postgres psql -U postgres -d saler -c "
        SELECT 
            datname as database,
            numbackends as connections,
            xact_commit as commits,
            xact_rollback as rollbacks,
            blks_read as reads,
            blks_hit as hits
        FROM pg_stat_database 
        WHERE datname = 'saler';
    "
}

# ÙØ­Øµ Redis
check_redis() {
    echo "ğŸ’¾ ÙØ­Øµ Redis..."
    
    docker-compose exec -T redis redis-cli info memory
    docker-compose exec -T redis redis-cli info stats
}

# ÙØ­Øµ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
check_logs() {
    echo "ğŸ“‹ ÙØ­Øµ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø£Ø®Ø·Ø§Ø¡..."
    
    echo "Ø¢Ø®Ø± 10 Ø£Ø®Ø·Ø§Ø¡:"
    tail -n 10 logs/error.log | grep ERROR
    
    echo "Ø¢Ø®Ø± 10 ØªØ­Ø°ÙŠØ±Ø§Øª:"
    tail -n 10 logs/app.log | grep WARNING
}

# ÙØ­Øµ SSL Ø§Ù„Ø´Ù‡Ø§Ø¯Ø§Øª
check_ssl() {
    echo "ğŸ”’ ÙØ­Øµ Ø´Ù‡Ø§Ø¯Ø§Øª SSL..."
    
    echo | openssl s_client -servername saler.app -connect saler.app:443 2>/dev/null | openssl x509 -noout -dates
}

# Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ±
send_report() {
    echo "ğŸ“¤ Ø¥Ø±Ø³Ø§Ù„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©..."
    
    report=$(cat << EOF
ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© - $(date)

Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø±Ø¯:
$(monitor_resources)

ÙØ­Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:
$(check_database)

ÙØ­Øµ Redis:
$(check_redis)

Ø¢Ø®Ø± Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:
$(tail -n 5 logs/error.log)

EOF
    )
    
    # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø¹Ø¨Ø± Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ
    echo "$report" | mail -s "ØªÙ‚Ø±ÙŠØ± Ù…Ø±Ø§Ù‚Ø¨Ø© Saler" admin@saler.app
    
    # Ø¥Ø±Ø³Ø§Ù„ Ø¥Ù„Ù‰ Slack (Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙØ¹Ù„)
    if [ ! -z "$SLACK_WEBHOOK_URL" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"ØªÙ‚Ø±ÙŠØ± Ù…Ø±Ø§Ù‚Ø¨Ø© Saler: $(date)\"}" \
            "$SLACK_WEBHOOK_URL"
    fi
}

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
case "$1" in
    "resources")
        monitor_resources
        ;;
    "database")
        check_database
        ;;
    "redis")
        check_redis
        ;;
    "logs")
        check_logs
        ;;
    "ssl")
        check_ssl
        ;;
    "report")
        send_report
        ;;
    *)
        echo "Ø§Ø³ØªØ®Ø¯Ø§Ù…: $0 {resources|database|redis|logs|ssl|report}"
        echo "ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ÙØ­ÙˆØµØ§Øª..."
        
        monitor_resources
        check_database
        check_redis
        check_logs
        check_ssl
        ;;
esac
```

## Security Considerations

### Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£Ù…Ø§Ù† Ù„Ù„Ù†Ø´Ø±

```bash
#!/bin/bash
# security-setup.sh - Ø¥Ø¹Ø¯Ø§Ø¯ Ø£Ù…Ø§Ù† Ø§Ù„Ù†Ø´Ø±

echo "ğŸ”’ Ø¥Ø¹Ø¯Ø§Ø¯ Ø£Ù…Ø§Ù† Ø§Ù„Ù†Ø´Ø±..."

# ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ø¸Ø§Ù…
sudo apt update && sudo apt upgrade -y

# ØªØ«Ø¨ÙŠØª Ø¬Ø¯Ø§Ø± Ø§Ù„Ø­Ù…Ø§ÙŠØ©
sudo ufw --force reset
sudo ufw default deny incoming
sudo ufw default allow outgoing
sudo ufw allow ssh
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw enable

# ØªØ«Ø¨ÙŠØª fail2ban
sudo apt install fail2ban -y

# Ø¥Ø¹Ø¯Ø§Ø¯ fail2ban Ù„Ù„Ø­Ù…Ø§ÙŠØ© Ù…Ù† Ù‡Ø¬Ù…Ø§Øª SSH
sudo tee /etc/fail2ban/jail.local > /dev/null <<EOF
[DEFAULT]
bantime = 3600
findtime = 600
maxretry = 3
destemail = admin@saler.app
sendername = Fail2Ban
mta = sendmail
action = %(action_mwl)s

[sshd]
enabled = true
port = ssh
filter = sshd
logpath = /var/log/auth.log
maxretry = 3
bantime = 3600
EOF

sudo systemctl enable fail2ban
sudo systemctl start fail2ban

# Ø¥Ø¹Ø¯Ø§Ø¯ SSL Ù…Ø¹ Let's Encrypt
sudo apt install certbot python3-certbot-nginx -y
sudo certbot --nginx -d saler.app -d www.saler.app

# Ø¥Ø¹Ø¯Ø§Ø¯ ØªØ¬Ø¯ÙŠØ¯ SSL Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
sudo crontab -l | grep -q "certbot renew" || (sudo crontab -l; echo "0 12 * * * /usr/bin/certbot renew --quiet") | sudo crontab -

echo "âœ… ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£Ù…Ø§Ù† Ø¨Ù†Ø¬Ø§Ø­!"
```

### Secure Configuration

```python
# config/security.py - Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†
import os
import secrets
from typing import List

class SecurityConfig:
    """Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£Ù…Ø§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
    
    # Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø£Ù…Ø§Ù†
    JWT_SECRET_KEY = os.getenv('JWT_SECRET_KEY', secrets.token_urlsafe(32))
    JWT_ACCESS_TOKEN_EXPIRES = 3600  # Ø³Ø§Ø¹Ø© ÙˆØ§Ø­Ø¯Ø©
    JWT_REFRESH_TOKEN_EXPIRES = 2592000  # 30 ÙŠÙˆÙ…
    JWT_ALGORITHM = 'HS256'
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±
    PASSWORD_MIN_LENGTH = 8
    PASSWORD_REQUIRE_SPECIAL = True
    PASSWORD_REQUIRE_NUMBERS = True
    PASSWORD_REQUIRE_UPPERCASE = True
    PASSWORD_REQUIRE_LOWERCASE = True
    PASSWORD_BAN_COMMON = True
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Rate Limiting
    RATELIMIT_STORAGE_URL = os.getenv('REDIS_URL', 'redis://localhost:6379/0')
    RATELIMIT_DEFAULT = "100/hour"
    RATELIMIT_API = "1000/hour"
    RATELIMIT_AUTH = "5/minute"
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª CORS
    CORS_ORIGINS = os.getenv('CORS_ORIGINS', 'https://saler.app').split(',')
    CORS_ALLOW_HEADERS = [
        'Authorization',
        'Content-Type',
        'X-Requested-With',
        'Accept',
        'Origin',
        'Access-Control-Request-Method',
        'Access-Control-Request-Headers'
    ]
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª CSP
    CONTENT_SECURITY_POLICY = {
        'default-src': "'self'",
        'script-src': "'self' 'unsafe-inline' 'unsafe-eval'",
        'style-src': "'self' 'unsafe-inline'",
        'img-src': "'self' data: https:",
        'font-src': "'self'",
        'connect-src': "'self' wss: https:",
        'frame-src': "'none'",
        'object-src': "'none'",
        'base-uri': "'self'",
        'form-action': "'self'"
    }
    
    # Session Security
    SESSION_COOKIE_SECURE = True
    SESSION_COOKIE_HTTPONLY = True
    SESSION_COOKIE_SAMESITE = 'Lax'
    PERMANENT_SESSION_LIFETIME = 3600
    
    # Database Security
    DATABASE_SSL_MODE = 'require'
    DATABASE_CONNECTION_TIMEOUT = 30
    DATABASE_POOL_SIZE = 10
    DATABASE_POOL_TIMEOUT = 30
    DATABASE_POOL_RECYCLE = 3600
    
    # Redis Security
    REDIS_PASSWORD = os.getenv('REDIS_PASSWORD')
    REDIS_SSL = True
    
    @classmethod
    def get_secure_headers(cls) -> dict:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¤ÙˆØ³ Ø§Ù„Ø£Ù…Ø§Ù† Ø§Ù„Ø¢Ù…Ù†Ø©"""
        return {
            'X-Content-Type-Options': 'nosniff',
            'X-Frame-Options': 'DENY',
            'X-XSS-Protection': '1; mode=block',
            'Strict-Transport-Security': 'max-age=31536000; includeSubDomains',
            'Referrer-Policy': 'strict-origin-when-cross-origin',
            'Content-Security-Policy': '; '.join([
                f'{key} {value}' for key, value in cls.CONTENT_SECURITY_POLICY.items()
            ])
        }
    
    @classmethod
    def validate_password_strength(cls, password: str) -> tuple[bool, List[str]]:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù‚ÙˆØ© ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ±"""
        errors = []
        
        if len(password) < cls.PASSWORD_MIN_LENGTH:
            errors.append(f'ÙŠØ¬Ø¨ Ø£Ù† ØªÙƒÙˆÙ† ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± {cls.PASSWORD_MIN_LENGTH} Ø£Ø­Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„')
        
        if cls.PASSWORD_REQUIRE_UPPERCASE and not any(c.isupper() for c in password):
            errors.append('ÙŠØ¬Ø¨ Ø£Ù† ØªØ­ØªÙˆÙŠ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ Ø­Ø±Ù ÙƒØ¨ÙŠØ± ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„')
        
        if cls.PASSWORD_REQUIRE_LOWERCASE and not any(c.islower() for c in password):
            errors.append('ÙŠØ¬Ø¨ Ø£Ù† ØªØ­ØªÙˆÙŠ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ Ø­Ø±Ù ØµØºÙŠØ± ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„')
        
        if cls.PASSWORD_REQUIRE_NUMBERS and not any(c.isdigit() for c in password):
            errors.append('ÙŠØ¬Ø¨ Ø£Ù† ØªØ­ØªÙˆÙŠ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ Ø±Ù‚Ù… ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„')
        
        if cls.PASSWORD_REQUIRE_SPECIAL and not any(c in '!@#$%^&*()_+-=[]{}|;:,.<>?' for c in password):
            errors.append('ÙŠØ¬Ø¨ Ø£Ù† ØªØ­ØªÙˆÙŠ ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø¹Ù„Ù‰ Ø±Ù…Ø² Ø®Ø§Øµ ÙˆØ§Ø­Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„')
        
        if cls.PASSWORD_BAN_COMMON:
            common_passwords = ['password', '123456', 'qwerty', 'admin', 'letmein']
            if password.lower() in common_passwords:
                errors.append('ÙƒÙ„Ù…Ø© Ø§Ù„Ù…Ø±ÙˆØ± Ø´Ø§Ø¦Ø¹Ø© Ø¬Ø¯Ø§Ù‹ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± ÙƒÙ„Ù…Ø© Ù…Ø±ÙˆØ± Ø£Ø®Ø±Ù‰')
        
        return len(errors) == 0, errors
```

## Rollback Strategies

### Ø®Ø·Ø© Ø§Ù„ØªØ±Ø§Ø¬Ø¹

```bash
#!/bin/bash
# rollback.sh - Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„ØªØ±Ø§Ø¬Ø¹

set -e  # Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª ÙÙŠ Ø­Ø§Ù„Ø© Ø®Ø·Ø£

ROLLBACK_DIR="/var/www/saler/backups"
CURRENT_DIR="/var/www/saler"
APP_NAME="saler-app"

echo "ğŸ”„ Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±Ø§Ø¬Ø¹..."

# Ø¹Ø±Ø¶ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù…ØªØ§Ø­Ø©
echo "ğŸ“‹ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù…ØªØ§Ø­Ø©:"
ls -la "$ROLLBACK_DIR"/"$APP_NAME"_* | tail -10

# Ø·Ù„Ø¨ ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
read -p "Ù‡Ù„ ØªØ±ÙŠØ¯ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ù…Ø¹ Ø§Ù„ØªØ±Ø§Ø¬Ø¹ØŸ (y/N): " -n 1 -r
echo
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±Ø§Ø¬Ø¹"
    exit 0
fi

# ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¥Ù„ÙŠÙ‡Ø§
if [ ! -z "$1" ]; then
    BACKUP_VERSION="$1"
else
    echo "Ø§Ø®ØªØ± Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¥Ù„ÙŠÙ‡Ø§:"
    ls "$ROLLBACK_DIR"/"$APP_NAME"_* | sort | tail -5
    read -p "Ø£Ø¯Ø®Ù„ Ø§Ø³Ù… Ø§Ù„Ù†Ø³Ø®Ø© (Ù…Ø«Ù„: saler-app_20240101_120000): " BACKUP_VERSION
fi

BACKUP_PATH="$ROLLBACK_DIR/$BACKUP_VERSION"

if [ ! -d "$BACKUP_PATH" ]; then
    echo "âŒ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø¯Ø¯Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©: $BACKUP_PATH"
    exit 1
fi

echo "ğŸ”„ Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø³Ø®Ø©: $BACKUP_VERSION"

# Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙƒÙ†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù„Ù„Ø·ÙˆØ§Ø±Ø¦
echo "ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©..."
BACKUP_TIMESTAMP=$(date +%Y%m%d_%H%M%S)
BACKUP_CURRENT="$ROLLBACK_DIR/emergency_$BACKUP_TIMESTAMP"
sudo cp -r "$CURRENT_DIR" "$BACKUP_CURRENT"
echo "âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© ÙÙŠ: $BACKUP_CURRENT"

# Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©
echo "â¹ï¸ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø¯Ù…Ø§Øª..."
cd "$CURRENT_DIR"
docker-compose down

# Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
echo "ğŸ“¦ Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù†Ø³Ø®Ø©..."
sudo rm -rf "$CURRENT_DIR"/*
sudo cp -r "$BACKUP_PATH"/* "$CURRENT_DIR/"

# Ø¶Ø¨Ø· Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
sudo chown -R saler:saler "$CURRENT_DIR"
sudo chmod +x "$CURRENT_DIR/deploy.sh"

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
echo "â–¶ï¸ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª..."
cd "$CURRENT_DIR"
docker-compose up -d

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
echo "ğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª..."
sleep 30

# ÙØ­Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
echo "ğŸ—„ï¸ ÙØ­Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."
if docker-compose exec postgres pg_isready -U postgres; then
    echo "âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ"
else
    echo "âŒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"
    exit 1
fi

# ÙØ­Øµ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
echo "ğŸŒ ÙØ­Øµ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚..."
if curl -f http://localhost:3000/health > /dev/null 2>&1; then
    echo "âœ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ"
else
    echo "âŒ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"
    echo "ğŸ”„ Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ù„Ù„Ø·ÙˆØ§Ø±Ø¦..."
    # Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ù„Ù„Ø·ÙˆØ§Ø±Ø¦
    sudo rm -rf "$CURRENT_DIR"/*
    sudo cp -r "$BACKUP_CURRENT"/* "$CURRENT_DIR/"
    docker-compose up -d
    echo "âœ… ØªÙ… Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ù„Ù„Ø·ÙˆØ§Ø±Ø¦"
    exit 1
fi

# Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø±
echo "ğŸ“§ Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø´Ø¹Ø§Ø± Ø§Ù„ØªØ±Ø§Ø¬Ø¹..."
echo "ØªÙ… Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¨Ù†Ø¬Ø§Ø­ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø³Ø®Ø© $BACKUP_VERSION ÙÙŠ $(date)" | mail -s "ØªÙ‚Ø±ÙŠØ± ØªØ±Ø§Ø¬Ø¹ Saler" admin@saler.app

echo "âœ… ØªÙ…Øª Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¨Ù†Ø¬Ø§Ø­!"
echo "ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø³Ø®Ø©:"
echo "   Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©: $BACKUP_VERSION"
echo "   Ù†Ø³Ø®Ø© Ø§Ù„Ø·ÙˆØ§Ø±Ø¦: $BACKUP_CURRENT"
```

### Automated Rollback

```yaml
# .github/workflows/rollback.yml
name: Emergency Rollback

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Ù†Ø³Ø®Ø© Ø§Ù„ØªØ±Ø§Ø¬Ø¹'
        required: true
        type: string
        default: 'latest'
      environment:
        description: 'Ø§Ù„Ø¨ÙŠØ¦Ø©'
        required: true
        type: choice
        options:
        - staging
        - production
        default: 'staging'

jobs:
  rollback:
    runs-on: ubuntu-latest
    environment: ${{ github.event.inputs.environment }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        
      - name: Execute rollback
        run: |
          echo "ğŸ”„ Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¥Ù„Ù‰ Ø§Ù„Ù†Ø³Ø®Ø©: ${{ github.event.inputs.version }}"
          
          # SSH Ø¥Ù„Ù‰ Ø§Ù„Ø®Ø§Ø¯Ù… ÙˆØªÙ†ÙÙŠØ° Ø§Ù„ØªØ±Ø§Ø¬Ø¹
          ssh ${{ secrets.REMOTE_USER }}@${{ secrets.REMOTE_HOST }} "
            cd /var/www/saler
            ./rollback.sh ${{ github.event.inputs.version }}
          "
          
      - name: Verify rollback
        run: |
          echo "ğŸ” Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†Ø¬Ø§Ø­ Ø§Ù„ØªØ±Ø§Ø¬Ø¹..."
          
          # ÙØ­Øµ ØµØ­Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
          curl -f https://${{ secrets.DOMAIN }}/health
          
          # ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©
          npm run test:smoke
          
      - name: Notify team
        if: always()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: |
            Ø§Ù„ØªØ±Ø§Ø¬Ø¹ ${{ job.status == 'success' && 'ØªÙ… Ø¨Ù†Ø¬Ø§Ø­' || 'ÙØ´Ù„' }}
            Ø§Ù„Ù†Ø³Ø®Ø©: ${{ github.event.inputs.version }}
            Ø§Ù„Ø¨ÙŠØ¦Ø©: ${{ github.event.inputs.environment }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
```

### Monitoring Rollback

```python
# scripts/rollback_monitor.py
import requests
import time
import json
from datetime import datetime
import logging

def monitor_rollback():
    """Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±Ø§Ø¬Ø¹"""
    
    health_url = "https://saler.app/health"
    api_url = "https://saler.app/api/v1/stats"
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
    logging.basicConfig(
        filename='rollback_monitor.log',
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    print("ğŸ” Ø¨Ø¯Ø¡ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ±Ø§Ø¬Ø¹...")
    
    start_time = time.time()
    failures = 0
    max_failures = 5
    
    while time.time() - start_time < 1800:  # 30 Ø¯Ù‚ÙŠÙ‚Ø© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰
        try:
            # ÙØ­Øµ ØµØ­Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
            health_response = requests.get(health_url, timeout=10)
            if health_response.status_code == 200:
                print(f"âœ… Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ - {datetime.now()}")
                failures = 0
            else:
                failures += 1
                print(f"âš ï¸ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØµØ­Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ - {health_response.status_code}")
                
            # ÙØ­Øµ API
            api_response = requests.get(api_url, timeout=10)
            if api_response.status_code == 200:
                print("âœ… API ÙŠØ¹Ù…Ù„ Ø¨Ø´ÙƒÙ„ Ø·Ø¨ÙŠØ¹ÙŠ")
            else:
                failures += 1
                print(f"âš ï¸ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ API - {api_response.status_code}")
                
            if failures >= max_failures:
                logging.error(f"ÙØ´Ù„ Ù…ØªÙƒØ±Ø±: {failures} Ø£Ø®Ø·Ø§Ø¡")
                send_alert("ÙØ´Ù„ Ù…ØªÙƒØ±Ø± ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ±Ø§Ø¬Ø¹")
                break
                
        except Exception as e:
            failures += 1
            error_msg = f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©: {e}"
            print(f"âŒ {error_msg}")
            logging.error(error_msg)
            
            if failures >= max_failures:
                send_alert(error_msg)
                break
        
        time.sleep(30)  # ÙØ­Øµ ÙƒÙ„ 30 Ø«Ø§Ù†ÙŠØ©
    
    print("âœ… Ø§Ù†ØªÙ‡Øª Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ±Ø§Ø¬Ø¹")
    logging.info("Ø§Ù†ØªÙ‡Øª Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¨Ù†Ø¬Ø§Ø­")

def send_alert(message):
    """Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡"""
    # Ø¥Ø±Ø³Ø§Ù„ ØªÙ†Ø¨ÙŠÙ‡ Ù„Ù„Ø¥Ø¯Ø§Ø±Ø©
    webhook_url = os.getenv('SLACK_WEBHOOK_URL')
    if webhook_url:
        requests.post(webhook_url, json={
            'text': f'ğŸš¨ ØªÙ†Ø¨ÙŠÙ‡: {message}',
            'channel': '#alerts'
        })

if __name__ == "__main__":
    monitor_rollback()
```

## Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª Ù„Ù„Ù†Ø´Ø±

### 1. Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ù†Ø´Ø±

- Ø§Ø³ØªØ®Ø¯Ù… Blue-Green Deployment
- Ù‚Ù… Ø¨Ø¹Ù…Ù„ Ù†Ø´Ø± ØªØ¯Ø±ÙŠØ¬ÙŠ (Canary Deployment)
- Ø§Ø®ØªØ¨Ø± ÙƒÙ„ Ù…Ø±Ø­Ù„Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ù„Ù„ØªØ§Ù„ÙŠØ©
- Ø§Ø­ØªÙØ¸ Ø¨Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯

### 2. Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©

- Ø±Ø§Ù‚Ø¨ Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¨Ø¹Ø¯ Ø§Ù„Ù†Ø´Ø±
- Ø±Ø§Ù‚Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
- Ø±Ø§Ù‚Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
- Ø§Ø­ØªÙØ¸ Ø¨Ø³Ø¬Ù„Ø§Øª Ù…ÙØµÙ„Ø©

### 3. Ø§Ù„Ø£Ù…Ø§Ù†

- Ø§Ø³ØªØ®Ø¯Ù… HTTPS Ø¯Ø§Ø¦Ù…Ø§Ù‹
- Ù‚Ù… Ø¨ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªØ¨Ø¹ÙŠØ§Øª Ø¨Ø§Ù†ØªØ¸Ø§Ù…
- Ø§Ø³ØªØ®Ø¯Ù… Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø© Ù„Ù„Ø£Ø³Ø±Ø§Ø±
- ÙØ¹Ù‘Ù„ Ø¬Ø¯Ø§Ø± Ø§Ù„Ø­Ù…Ø§ÙŠØ©

### 4. Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©

- Ø¹Ù…Ù„ Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
- Ø§Ø®ØªØ¨Ø§Ø± Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯
- Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ù†Ø³Ø® Ù…ØªØ¹Ø¯Ø¯Ø©
- ØªÙˆØ«ÙŠÙ‚ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø§Ø³ØªØ±Ø¯Ø§Ø¯

---

Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙŠÙˆÙØ± Ù†Ø¸Ø±Ø© Ø´Ø§Ù…Ù„Ø© Ø¹Ù„Ù‰ Ø¹Ù…Ù„ÙŠØ© Ù†Ø´Ø± ØªØ·Ø¨ÙŠÙ‚ Saler Ù…Ù† Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø­Ù„ÙŠ Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ Ù…Ø¹ Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù…Ø§Ù†ØŒ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©ØŒ ÙˆØ¥Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ±Ø§Ø¬Ø¹.