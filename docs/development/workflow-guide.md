# ğŸ”„ Ø¯Ù„ÙŠÙ„ Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ ÙÙŠ Ø§Ù„ØªØ·ÙˆÙŠØ± - Saler Development Workflow

## Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙŠÙˆØ¶Ø­ Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ø«Ø§Ù„ÙŠ Ù„ØªØ·ÙˆÙŠØ± Saler Ù…Ù† Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø¥Ù„Ù‰ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ Ù…Ø¹ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©.

## Ø¨Ù†ÙŠØ© Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„

```
Development â†’ Testing â†’ Code Review â†’ Staging â†’ Production
     â†“              â†“           â†“          â†“          â†“
   Feature     Integration   PR Review   Deploy     Monitor
   Branches     Tests       Merge       Staging     Health
```

## Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø©

### Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„ÙŠÙˆÙ…ÙŠ

```bash
# 1. ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
git pull origin main

# 2. Ø¨Ø¯Ø¡ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±
./scripts/dev.sh start

# 3. ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª
./scripts/dev.sh status

# 4. ÙØ­Øµ Ø¢Ø®Ø± Ø§Ù„Ø³Ø¬Ù„Ø§Øª
./scripts/dev.sh logs --tail=20
```

### Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø£ÙˆÙ„ÙŠ Ù„Ù„Ù…Ø´Ø±ÙˆØ¹

```bash
# Ø¥Ø¹Ø¯Ø§Ø¯ Ø´Ø§Ù…Ù„ Ù„Ù„Ø¨ÙŠØ¦Ø©
./scripts/setup.sh

# ØªØ«Ø¨ÙŠØª Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ·ÙˆÙŠØ±
./scripts/tools.sh

# Ø¥Ø¹Ø¯Ø§Ø¯ IDE configurations
./scripts/ide.sh

# Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·ÙˆÙŠØ±
./scripts/dev.sh start --with-gui
```

## Ø³ÙŠØ± Ø¹Ù…Ù„ Git

### 1. Ø¥Ù†Ø´Ø§Ø¡ Feature Branch

```bash
# Ø¥Ù†Ø´Ø§Ø¡ branch Ø¬Ø¯ÙŠØ¯
git checkout -b feature/AI-lead-scoring

# Ø£Ùˆ Ù„Ù€ bug fix
git checkout -b fix/database-connection-issue

# Ø£Ùˆ Ù„Ù€ improvement
git checkout -b improvement/api-performance
```

### 2. Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Feature

```bash
# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒÙˆØ¯
# ... ØªØ·ÙˆÙŠØ± Ø§Ù„ÙƒÙˆØ¯ ...

# ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯
./scripts/dev.sh lint

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
./scripts/dev.sh test

# Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
./scripts/dev.sh format

# ÙØ­Øµ Git status
git status

# Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ù„ÙØ§Øª
git add .

# Ø¥Ù†Ø´Ø§Ø¡ commit Ù…Ø¹ Ø±Ø³Ø§Ù„Ø© ÙˆØ§Ø¶Ø­Ø©
git commit -m "feat: implement AI lead scoring algorithm

- Add machine learning model integration
- Implement real-time scoring endpoint
- Add comprehensive tests
- Update API documentation

Closes #123"
```

### 3. Git Hooks Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©

ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Git hooks ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø³ØªÙ‚ÙˆÙ… Ø¨Ù€:
- ÙØ­Øµ syntax Ù„Ù„Ø£Ø®Ø·Ø§Ø¡
- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† security issues
- ÙØ­Øµ TODO/FIXME comments
- Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† .gitignore configurations

### 4. Push Ùˆ Pull Request

```bash
# Ø±ÙØ¹ Ø§Ù„Ù€ branch
git push origin feature/AI-lead-scoring

# Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ PR Ù…Ù† GitHub/GitLab interface
# Ø«Ù… Ø¥Ù†Ø´Ø§Ø¡ merge request
```

### 5. Code Review Process

```markdown
## PR Template

### ÙˆØµÙ Ø§Ù„ØªØºÙŠÙŠØ±
ÙˆØµÙ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø®ØªØµØ± Ù„Ù„ØªØºÙŠÙŠØ±

### Ù†ÙˆØ¹ Ø§Ù„ØªØºÙŠÙŠØ±
- [ ] Bug fix (non-breaking change)
- [ ] New feature (non-breaking change)
- [ ] Breaking change
- [ ] Documentation update

### Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØºÙŠÙŠØ±
- [ ] Unit tests passing
- [ ] Integration tests passing
- [ ] Manual testing completed
- [ ] Performance impact assessed

### screenshots (Ø¥Ù† ÙˆØ¬Ø¯)
Ø¶Ø¹ screenshots Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØºÙŠÙŠØ±Ø§Øª ÙÙŠ UI
```

## Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª

### Python Development

#### Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
```bash
cd backend
source venv/bin/activate

# ØªØ«Ø¨ÙŠØª dependencies
pip install -r requirements.txt

# ØªØ«Ø¨ÙŠØª development dependencies
pip install -r requirements-dev.txt
```

#### ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
```bash
# Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
python -m pytest

# Ù…Ø¹ coverage
python -m pytest --cov=app

# Ù…Ø¹ detailed output
python -m pytest -v --tb=short

# watch mode (Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª)
ptw  # python-task-watch

# specific test
python -m pytest tests/test_lead_scoring.py::test_ai_scoring
```

#### Debugging
```python
# Ø§Ø³ØªØ®Ø¯Ø§Ù… Python Debugger
import pdb; pdb.set_trace()

# Ø£Ùˆ ÙÙŠ VS Code
# Set breakpoint and press F5

# Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… debug script
from scripts.debug.python_debug import debug_trace, memory_usage
debug_trace()
memory_usage()
```

#### Linting Ùˆ Formatting
```bash
# ÙØ­Øµ Ù…Ø¹ flake8
flake8 app/

# ØªÙ†Ø³ÙŠÙ‚ Ù…Ø¹ black
black app/

# ØªØ±ØªÙŠØ¨ imports Ù…Ø¹ isort
isort app/

# ÙØ­Øµ types Ù…Ø¹ mypy
mypy app/

# ÙØ­Øµ security Ù…Ø¹ bandit
bandit -r app/
```

### JavaScript/TypeScript Development

#### ØªØ´ØºÙŠÙ„ Frontend
```bash
cd frontend

# ØªØ´ØºÙŠÙ„ development server
npm run dev

# Ø¨Ù†Ø§Ø¡ Ù„Ù„Ø¥Ù†ØªØ§Ø¬
npm run build

# ØªØ´ØºÙŠÙ„ production server
npm start

# ÙØ­Øµ builds
npm run analyze
```

#### Testing
```bash
# ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
npm test

# watch mode
npm run test:watch

# Ù…Ø¹ coverage
npm run test:coverage

# specific test
npm test LeadScoring.test.tsx
```

#### Linting Ùˆ Formatting
```bash
# ÙØ­Øµ ESLint
npm run lint

# Ø¥ØµÙ„Ø§Ø­ ØªÙ„Ù‚Ø§Ø¦ÙŠ
npm run lint:fix

# ØªÙ†Ø³ÙŠÙ‚ Ù…Ø¹ Prettier
npx prettier --write src/

# ÙØ­Øµ TypeScript
npx tsc --noEmit
```

### Database Development

#### PostgreSQL Operations
```bash
# Ø§ØªØµØ§Ù„ Ù…Ø¨Ø§Ø´Ø±
psql-dev  # alias Ù…ÙØ¹Ø±ÙÙ‘Ù Ù…Ø³Ø¨Ù‚Ø§Ù‹

# Ø£Ùˆ
docker-compose exec postgres psql -U saler_user saler

# ØªØ´ØºÙŠÙ„ migrations
docker-compose exec backend python -m alembic upgrade head

# Ø¥Ù†Ø´Ø§Ø¡ migration Ø¬Ø¯ÙŠØ¯Ø©
docker-compose exec backend python -m alembic revision --autogenerate -m "Description"

# Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
./scripts/dev.sh db backup

# Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
./scripts/dev.sh db restore backup_20231201_143022.sql
```

#### Data Management
```sql
-- Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
\dt

-- Ø¹Ø±Ø¶ schema
\d+ table_name

-- Ø¹Ø±Ø¶ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
SELECT * FROM leads LIMIT 10;

-- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡
EXPLAIN ANALYZE SELECT * FROM leads WHERE score > 80;
```

### Redis Development

```bash
# Ø§ØªØµØ§Ù„ Ù…Ø¨Ø§Ø´Ø±
redis-cli  # alias Ù…ÙØ¹Ø±ÙÙ‘Ù Ù…Ø³Ø¨Ù‚Ø§Ù‹

# Ø£Ùˆ
docker-compose exec redis redis-cli

# Ù…Ø±Ø§Ù‚Ø¨Ø© Redis
redis-cli monitor

# Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
redis-cli info memory

# Ø¨Ø­Ø« ÙÙŠ keys
redis-cli keys "*lead*"
```

## Ø³ÙŠØ± Ø¹Ù…Ù„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±

### 1. Unit Testing

#### Python Tests
```python
# tests/test_lead_scoring.py
import pytest
from app.services.ai_scoring import AIScoringService

@pytest.fixture
def scoring_service():
    return AIScoringService()

def test_calculate_lead_score(scoring_service):
    # Arrange
    lead_data = {
        "name": "Ahmed Ali",
        "email": "ahmed@example.com",
        "phone": "+1234567890"
    }
    
    # Act
    score = scoring_service.calculate_score(lead_data)
    
    # Assert
    assert 0 <= score <= 100
    assert isinstance(score, float)

@pytest.mark.asyncio
async def test_real_time_scoring(scoring_service):
    # Test async operations
    result = await scoring_service.predict_async(test_data)
    assert result.status == "success"
```

#### JavaScript Tests
```typescript
// tests/components/LeadCard.test.tsx
import { render, screen, fireEvent } from '@testing-library/react';
import { LeadCard } from '@/components/LeadCard';

describe('LeadCard', () => {
  const mockLead = {
    id: '1',
    name: 'Ahmed Ali',
    email: 'ahmed@example.com',
    score: 85
  };

  it('renders lead information correctly', () => {
    render(<LeadCard lead={mockLead} />);
    
    expect(screen.getByText('Ahmed Ali')).toBeInTheDocument();
    expect(screen.getByText('ahmed@example.com')).toBeInTheDocument();
    expect(screen.getByText('85')).toBeInTheDocument();
  });

  it('handles click events', () => {
    const onClick = jest.fn();
    render(<LeadCard lead={mockLead} onClick={onClick} />);
    
    fireEvent.click(screen.getByRole('button'));
    expect(onClick).toHaveBeenCalledWith(mockLead);
  });
});
```

### 2. Integration Testing

```python
# tests/integration/test_api_endpoints.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_create_lead_endpoint():
    response = client.post("/api/v1/leads", json={
        "name": "Ahmed Ali",
        "email": "ahmed@example.com"
    })
    
    assert response.status_code == 201
    data = response.json()
    assert "id" in data
    assert data["name"] == "Ahmed Ali"
```

```typescript
// tests/integration/api.test.ts
import { setupTestEnvironment, cleanupTestEnvironment } from '../test-utils';

describe('Lead API Integration', () => {
  beforeAll(async () => {
    await setupTestEnvironment();
  });

  afterAll(async () => {
    await cleanupTestEnvironment();
  });

  it('should create and retrieve lead', async () => {
    // Create lead
    const createResponse = await fetch('/api/v1/leads', {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        name: 'Ahmed Ali',
        email: 'ahmed@example.com'
      })
    });

    expect(createResponse.status).toBe(201);
    const lead = await createResponse.json();

    // Retrieve lead
    const getResponse = await fetch(`/api/v1/leads/${lead.id}`);
    expect(getResponse.status).toBe(200);
    
    const retrievedLead = await getResponse.json();
    expect(retrievedLead.name).toBe('Ahmed Ali');
  });
});
```

### 3. End-to-End Testing

```typescript
// cypress/integration/lead-management.spec.ts
describe('Lead Management Flow', () => {
  beforeEach(() => {
    cy.visit('/leads');
    cy.login('admin@example.com', 'password');
  });

  it('should create new lead and verify scoring', () => {
    // Create new lead
    cy.get('[data-testid="new-lead-button"]').click();
    cy.get('[data-testid="lead-name"]').type('Ahmed Ali');
    cy.get('[data-testid="lead-email"]').type('ahmed@example.com');
    cy.get('[data-testid="lead-phone"]').type('+1234567890');
    cy.get('[data-testid="submit-lead"]').click();

    // Verify lead appears in list
    cy.get('[data-testid="lead-card"]')
      .should('contain', 'Ahmed Ali')
      .and('contain', 'ahmed@example.com');

    // Verify AI scoring
    cy.get('[data-testid="ai-score"]')
      .should('be.visible')
      .and('contain', 'Score:');
  });
});
```

## Performance Monitoring

### 1. Application Monitoring

```python
# Backend metrics
from prometheus_client import Counter, Histogram, generate_latest
import time

# Define metrics
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint'])
REQUEST_LATENCY = Histogram('http_request_duration_seconds', 'HTTP request latency')

@app.middleware("http")
async def monitor_requests(request: Request, call_next):
    start_time = time.time()
    response = await call_next(request)
    process_time = time.time() - start_time
    
    REQUEST_COUNT.labels(
        method=request.method,
        endpoint=request.url.path
    ).inc()
    
    REQUEST_LATENCY.observe(process_time)
    
    return response
```

### 2. Database Performance

```sql
-- Enable query logging
ALTER SYSTEM SET log_statement = 'all';
ALTER SYSTEM SET log_min_duration_statement = 1000; -- Log queries > 1s
SELECT pg_reload_conf();

-- Monitor slow queries
SELECT query, mean_exec_time, calls, total_exec_time
FROM pg_stat_statements
ORDER BY mean_exec_time DESC
LIMIT 10;
```

### 3. Frontend Performance

```typescript
// Performance monitoring
export const measurePerformance = (name: string, fn: () => Promise<any>) => {
  const start = performance.now();
  return fn().then((result) => {
    const end = performance.now();
    console.log(`${name} took ${end - start} milliseconds`);
    return result;
  });
};

// Usage
const fetchLeads = measurePerformance('fetchLeads', async () => {
  const response = await fetch('/api/leads');
  return response.json();
});
```

## Error Handling Ùˆ Logging

### 1. Structured Logging

```python
# Python logging configuration
import logging
import structlog

structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

logger = structlog.get_logger()

# Usage
logger.info("Lead processing started", lead_id=lead.id, user_id=user.id)
logger.error("AI scoring failed", error=str(e), lead_id=lead.id)
```

```typescript
// TypeScript logging
import winston from 'winston';

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: 'logs/app.log' })
  ]
});

// Usage
logger.info('Lead processing started', { leadId: lead.id, userId: user.id });
logger.error('AI scoring failed', { error: e.message, leadId: lead.id });
```

### 2. Error Boundaries

```typescript
// React Error Boundary
export class ErrorBoundary extends React.Component<
  { children: React.ReactNode },
  { hasError: boolean; error?: Error }
> {
  constructor(props: { children: React.ReactNode }) {
    super(props);
    this.state = { hasError: false };
  }

  static getDerivedStateFromError(error: Error) {
    return { hasError: true, error };
  }

  componentDidCatch(error: Error, errorInfo: React.ErrorInfo) {
    // Log error to monitoring service
    console.error('Error caught by boundary:', error, errorInfo);
    
    // Send to error tracking service
    // errorTrackingService.captureException(error, { extra: errorInfo });
  }

  render() {
    if (this.state.hasError) {
      return (
        <div className="error-fallback">
          <h2>Something went wrong.</h2>
          <details>
            <summary>Error details</summary>
            <pre>{this.state.error?.stack}</pre>
          </details>
        </div>
      );
    }

    return this.props.children;
  }
}
```

## Security Best Practices

### 1. Environment Variables

```bash
# .env.local (Ù„Ø§ ÙŠØªÙ… commit)
DATABASE_URL=postgresql://user:pass@localhost:5432/db
SECRET_KEY=your-very-secure-secret-key
OPENAI_API_KEY=sk-...

# .env.example (ÙŠØªÙ… commit)
DATABASE_URL=postgresql://user:password@localhost:5432/database_name
SECRET_KEY=your-secret-key-here
OPENAI_API_KEY=your-openai-api-key-here
```

### 2. Input Validation

```python
# Pydantic models
from pydantic import BaseModel, EmailStr, validator

class LeadCreate(BaseModel):
    name: str = Field(..., min_length=1, max_length=100)
    email: EmailStr
    phone: str = Field(..., regex=r'^\+?[1-9]\d{1,14}$')
    
    @validator('name')
    def name_must_contain_space(cls, v):
        if ' ' not in v:
            raise ValueError('must contain a space')
        return v

@app.post("/leads")
async def create_lead(lead: LeadCreate):
    # lead is automatically validated
    pass
```

```typescript
// Zod validation
import { z } from 'zod';

const LeadSchema = z.object({
  name: z.string().min(1).max(100),
  email: z.string().email(),
  phone: z.string().regex(/^\+?[1-9]\d{1,14}$/)
});

export const createLead = (data: unknown) => {
  const validated = LeadSchema.parse(data);
  // validated data is type-safe
};
```

### 3. API Security

```python
# Rate limiting
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/leads")
@limiter.limit("10/minute")
async def create_lead(request: Request, lead: LeadCreate):
    # Implementation
    pass

# Authentication
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from jose import JWTError, jwt

security = HTTPBearer()

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    try:
        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Invalid authentication credentials")
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid authentication credentials")
    return user_id
```

## Deployment Workflow

### 1. Staging Environment

```bash
# Ø¨Ù†Ø§Ø¡ Ù„Ù„Ø¥Ù†ØªØ§Ø¬
docker-compose -f docker-compose.staging.yml build

# Ø§Ø®ØªØ¨Ø§Ø± ÙÙŠ staging
docker-compose -f docker-compose.staging.yml up -d

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ÙÙŠ staging
./scripts/ci/staging-tests.sh
```

### 2. Production Deployment

```bash
# Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
./scripts/dev.sh db backup

# Ø¨Ù†Ø§Ø¡ production images
docker-compose -f docker-compose.prod.yml build --no-cache

# Ù†Ø´Ø± Ø¥Ù„Ù‰ production
docker-compose -f docker-compose.prod.yml up -d

# Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
./scripts/monitoring/health-check.sh
```

### 3. Monitoring Ùˆ Alerts

```yaml
# docker/prometheus/rules.yml
groups:
- name: saler.rules
  rules:
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: High error rate detected
      description: "Error rate is {{ $value }} errors per second"
      
  - alert: DatabaseConnectionsHigh
    expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.8
    for: 2m
    labels:
      severity: warning
    annotations:
      summary: Database connections are high
      description: "Database connection usage is {{ $value | humanizePercentage }}"
```

## Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ©

### 1. Aliases Ø³Ø±ÙŠØ¹Ø©

```bash
# Ø£Ø¶Ù Ø¥Ù„Ù‰ .bashrc Ø£Ùˆ .zshrc
alias saler-dev='./scripts/dev.sh start --with-gui'
alias saler-test='./scripts/dev.sh test'
alias saler-lint='./scripts/dev.sh lint'
alias saler-format='./scripts/dev.sh format'
alias saler-backup='./scripts/dev.sh db backup'
alias saler-logs='./scripts/dev.sh logs'
```

### 2. IDE Shortcuts

```json
// VS Code keybindings.json
[
  {
    "key": "ctrl+shift+d",
    "command": "workbench.action.tasks.runTask",
    "args": "Start Development Services"
  },
  {
    "key": "ctrl+shift+t",
    "command": "workbench.action.tasks.runTask",
    "args": "Run Tests"
  },
  {
    "key": "ctrl+shift+l",
    "command": "workbench.action.tasks.runTask",
    "args": "Lint Code"
  }
]
```

### 3. Automation Scripts

```bash
#!/bin/bash
# scripts/daily-workflow.sh

echo "ğŸŒ… Starting daily development workflow..."

# Update code
echo "ğŸ“¥ Pulling latest changes..."
git pull origin main

# Start development environment
echo "ğŸš€ Starting development environment..."
./scripts/dev.sh start --with-gui

# Run quick tests
echo "ğŸ§ª Running quick tests..."
cd backend && python -m pytest --maxfail=1 -q

# Open useful tools
echo "ğŸ”§ Opening development tools..."
open http://localhost:3000  # Frontend
open http://localhost:8000/docs  # API docs
open http://localhost:8080  # pgAdmin

echo "âœ… Daily workflow completed! Happy coding! ğŸ‰"
```

## Ø®Ù„Ø§ØµØ©

Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙŠÙˆÙØ± framework Ø´Ø§Ù…Ù„ Ù„Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„ÙØ¹Ø§Ù„. Ø§Ù„Ù…ÙØªØ§Ø­ Ù‡Ùˆ:

1. **Ø§ØªØ¨Ø¹ Process Ø«Ø§Ø¨Øª** Ù„Ù„ØªØ·ÙˆÙŠØ±
2. **Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©** Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø±
3. **Ø±Ø§Ù‚Ø¨ Ø§Ù„Ø¬ÙˆØ¯Ø©** ÙÙŠ ÙƒÙ„ Ù…Ø±Ø­Ù„Ø©
4. **Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙØ¹Ø¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹** Ù„Ù„ØªÙˆÙÙŠØ± ÙÙŠ Ø§Ù„ÙˆÙ‚Øª
5. **ØªÙˆØ«Ù‚ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª** ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ§Øª

Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ØŒ Ø§Ø¨Ø¯Ø£ Ø¨Ù€ [Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹](./quick-start.md) Ø«Ù… Ø§Ø±Ø¬Ø¹ Ù„Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©.