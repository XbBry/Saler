# ğŸ¤ Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© - Contribution Guidelines

## Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

Ù†Ø±Ø­Ø¨ Ø¨Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø§Øª Ù„ØªØ·ÙˆÙŠØ± Saler! Ù‡Ø°Ø§ Ø§Ù„Ø¯Ù„ÙŠÙ„ ÙŠÙˆØ¶Ø­ ÙƒÙŠÙÙŠØ© Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© Ø¨Ø·Ø±ÙŠÙ‚Ø© ÙØ¹Ø§Ù„Ø© ÙˆÙ…Ù‡Ù†ÙŠØ©.

## ÙÙ‡Ø±Ø³ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª

- [ÙƒÙŠÙÙŠØ© Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©](#ÙƒÙŠÙÙŠØ©-Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©)
- [Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±](#Ø¥Ø¹Ø¯Ø§Ø¯-Ø¨ÙŠØ¦Ø©-Ø§Ù„ØªØ·ÙˆÙŠØ±)
- [Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ·ÙˆÙŠØ±](#Ø¹Ù…Ù„ÙŠØ©-Ø§Ù„ØªØ·ÙˆÙŠØ±)
- [ÙƒØªØ§Ø¨Ø© Ø§Ù„ÙƒÙˆØ¯](#ÙƒØªØ§Ø¨Ø©-Ø§Ù„ÙƒÙˆØ¯)
- [Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±](#Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±)
- [ØªÙˆØ«ÙŠÙ‚ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª](#ØªÙˆØ«ÙŠÙ‚-Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª)
- [Pull Request Process](#pull-request-process)
- [Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙƒÙˆØ¯](#Ù…Ø±Ø§Ø¬Ø¹Ø©-Ø§Ù„ÙƒÙˆØ¯)
- [Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¬ÙˆØ¯Ø©](#Ù…Ø¹Ø§ÙŠÙŠØ±-Ø§Ù„Ø¬ÙˆØ¯Ø©)

## ÙƒÙŠÙÙŠØ© Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©

### Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø§Øª

Ù†Ø±Ø­Ø¨ Ø¨Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø§Øª:

1. **ğŸ› Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ (Bug Fixes)**
   - Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
   - ØªØ­Ø³ÙŠÙ† stability
   - Ø¥ØµÙ„Ø§Ø­ performance issues

2. **âœ¨ Ø¥Ø¶Ø§ÙØ© Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© (New Features)**
   - Ù…ÙŠØ²Ø§Øª ØµØºÙŠØ±Ø© ÙˆÙ…ÙÙŠØ¯Ø©
   - ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ù„Ù€ UI/UX
   - ØªÙƒØ§Ù…Ù„Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ©

3. **ğŸ“š ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙˆØ«ÙŠÙ‚ (Documentation)**
   - Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚
   - Ø¥Ø¶Ø§ÙØ© Ø£Ù…Ø«Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©
   - ØªØ±Ø¬Ù…Ø© Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚

4. **ğŸ§ª Ø¥Ø¶Ø§ÙØ© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Tests)**
   - Unit tests
   - Integration tests
   - E2E tests

5. **âš¡ ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ (Performance)**
   - ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
   - ØªØ­Ø³ÙŠÙ† cache strategies
   - ØªØ­Ø³ÙŠÙ† front-end performance

### Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡

1. **ØªØ­Ù‚Ù‚ Ù…Ù† Issues Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©**
   - Ø§Ø¨Ø­Ø« ÙÙŠ GitHub Issues
   - ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù€ roadmap
   - ØªØ£ÙƒØ¯ Ù…Ù† Ø¹Ø¯Ù… ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¹Ù…Ù„

2. **Ø£Ù†Ø´Ø¦ Issue Ù„Ù…Ù†Ø§Ù‚Ø´Ø© Ø§Ù„ÙÙƒØ±Ø©**
   - ÙˆØµÙ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø£Ùˆ Ø§Ù„Ù…ÙŠØ²Ø©
   - Ø§Ù‚ØªØ±Ø­ Ø§Ù„Ø­Ù„ Ø§Ù„Ù…Ù‚ØªØ±Ø­
   - Ø§Ù†ØªØ¸Ø± Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡

## Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±

### Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª

- Git
- Python 3.11+
- Node.js 18+
- Docker & Docker Compose
- PostgreSQL 15+
- Redis 7+

### Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø©

```bash
# 1. Fork Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
git clone https://github.com/your-username/saler.git
cd saler

# 2. Ø¥Ø¶Ø§ÙØ© upstream remote
git remote add upstream https://github.com/original/saler.git

# 3. Ø¥Ø¹Ø¯Ø§Ø¯ Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±
./scripts/setup.sh

# 4. Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·ÙˆÙŠØ±
./scripts/dev.sh start --with-gui
```

### IDE Configuration

```bash
# Ø¥Ø¹Ø¯Ø§Ø¯ IDE configurations
./scripts/ide.sh

# ØªØ«Ø¨ÙŠØª VS Code extensions Ø§Ù„Ù…ÙÙˆØµÙ‰ Ø¨Ù‡Ø§
# (Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡Ø§ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹)
```

## Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ·ÙˆÙŠØ±

### Branch Strategy

Ù†Ø³ØªØ®Ø¯Ù… Git Flow Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª:

```bash
# Ø¥Ù†Ø´Ø§Ø¡ feature branch
git checkout -b feature/descriptive-feature-name

# Ø£Ùˆ Ù„Ù€ bug fix
git checkout -b fix/issue-description

# Ø£Ùˆ Ù„Ù€ improvement
git checkout -b improvement/description
```

#### Ø£Ù†ÙˆØ§Ø¹ Branches

- `main`: Production-ready code
- `develop`: Integration branch for features
- `feature/*`: New features
- `fix/*`: Bug fixes
- `hotfix/*`: Critical fixes for production
- `release/*`: Release preparation

### Workflow Ø§Ù„ÙŠÙˆÙ…ÙŠ

```bash
# 1. ØªØ­Ø¯ÙŠØ« main branch
git checkout main
git pull upstream main

# 2. Ø¥Ù†Ø´Ø§Ø¡ feature branch
git checkout -b feature/your-feature-name

# 3. ØªØ·ÙˆÙŠØ± Ø§Ù„ÙƒÙˆØ¯
# ... write code ...

# 4. ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
./scripts/dev.sh test

# 5. ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯
./scripts/dev.sh lint

# 6. commit Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
git add .
git commit -m "feat: add AI lead scoring feature

- Implement machine learning model integration
- Add real-time scoring endpoint
- Include comprehensive tests
- Update API documentation

Closes #123"

# 7. Ø±ÙØ¹ Ø§Ù„Ù€ branch
git push origin feature/your-feature-name
```

## ÙƒØªØ§Ø¨Ø© Ø§Ù„ÙƒÙˆØ¯

### Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ÙƒÙˆØ¯

#### Python

```python
# âœ… Ø§Ø³ØªØ®Ø¯Ù… type hints
def calculate_lead_score(
    lead_data: Dict[str, Any],
    model_version: str = "v2.0"
) -> Optional[float]:
    """Calculate AI-powered lead score.
    
    Args:
        lead_data: Raw lead information
        model_version: AI model version to use
        
    Returns:
        Calculated score or None if calculation fails
        
    Raises:
        ValidationError: If lead data is invalid
        ModelError: If AI model fails
    """
    pass

# âœ… Ø§Ø³ØªØ®Ø¯Ù… docstrings ÙˆØ§Ø¶Ø­Ø©
async def process_lead_async(
    lead: LeadCreate,
    scoring_service: AIScoringService
) -> Lead:
    """Process a lead asynchronously with AI scoring.
    
    This function handles the complete lead processing workflow including
    validation, AI scoring, and database persistence.
    
    Args:
        lead: Lead data to process
        scoring_service: AI scoring service instance
        
    Returns:
        Processed Lead object with calculated score
        
    Example:
        >>> lead_data = LeadCreate(name="Ahmed", email="ahmed@example.com")
        >>> processed = await process_lead_async(lead_data, scoring_service)
        >>> print(f"Score: {processed.score}")
    """
    pass
```

#### JavaScript/TypeScript

```typescript
// âœ… Ø§Ø³ØªØ®Ø¯Ù… TypeScript types
interface LeadData {
  readonly id: string;
  name: string;
  email: string;
  score?: number;
}

export class LeadService {
  constructor(private readonly apiClient: ApiClient) {}
  
  async createLead(data: LeadData): Promise<Lead> {
    // Implementation
  }
  
  async getLeads(filters?: LeadFilters): Promise<Lead[]> {
    // Implementation
  }
}

// âœ… Ø§Ø³ØªØ®Ø¯Ù… JSDoc documentation
/**
 * Calculate lead score using AI model.
 * 
 * @param leadData - Raw lead information
 * @param options - Scoring options
 * @returns Promise that resolves to score result
 * 
 * @example
 * const result = await calculateLeadScore({
 *   name: "Ahmed Ali",
 *   email: "ahmed@example.com"
 * });
 */
export async function calculateLeadScore(
  leadData: LeadData,
  options: ScoringOptions = {}
): Promise<ScoringResult> {
  // Implementation
}
```

### Code Style

#### Python

```python
# .flake8 ÙÙŠ Ø§Ù„Ø¬Ø°Ø±
[flake8]
max-line-length = 88
extend-ignore = E203, W503
exclude = .git,__pycache__,venv,node_modules

# Black formatting
# Ø§Ø³ØªØ®Ø¯Ù… black Ù„ØªØ·Ø¨ÙŠÙ‚ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙƒÙˆØ¯
black app/ tests/

# isort Ù„Ù„Ù€ imports
isort app/ tests/

# mypy Ù„Ù„ÙØ­Øµ Ø§Ù„Ù†ÙˆØ¹ÙŠ
mypy app/
```

#### JavaScript/TypeScript

```json
// .eslintrc.json
{
  "extends": [
    "next/core-web-vitals",
    "@typescript-eslint/recommended"
  ],
  "rules": {
    "@typescript-eslint/no-unused-vars": "error",
    "@typescript-eslint/no-explicit-any": "warn",
    "prefer-const": "error",
    "no-console": "warn"
  }
}

// .prettierrc
{
  "singleQuote": true,
  "trailingComma": "es5",
  "tabWidth": 2,
  "printWidth": 88
}
```

## Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±

### Unit Testing

#### Python

```python
import pytest
from unittest.mock import Mock, patch
from app.services.ai_scoring import AIScoringService

class TestAIScoringService:
    @pytest.fixture
    def service(self):
        return AIScoringService()
    
    @pytest.mark.asyncio
    async def test_calculate_score_success(self, service):
        """Test successful score calculation."""
        # Arrange
        lead_data = {"name": "Ahmed", "email": "ahmed@example.com"}
        expected_score = 85.5
        
        with patch.object(service, '_call_ai_model') as mock_ai:
            mock_ai.return_value = {"score": expected_score}
            
            # Act
            result = await service.calculate_score_async(lead_data)
            
            # Assert
            assert result["score"] == expected_score
    
    def test_validation_error(self, service):
        """Test validation error handling."""
        # Arrange
        invalid_data = {"name": "", "email": "invalid"}
        
        # Act & Assert
        with pytest.raises(ValidationError):
            service.calculate_score_sync(invalid_data)
```

#### JavaScript

```typescript
import { render, screen, fireEvent } from '@testing-library/react';
import { LeadForm } from '@/components/LeadForm';

describe('LeadForm Component', () => {
  it('should create lead when form is submitted', async () => {
    // Arrange
    const onSubmit = jest.fn();
    render(<LeadForm onSubmit={onSubmit} />);
    
    // Act
    fireEvent.change(screen.getByLabelText(/name/i), {
      target: { value: 'Ahmed Ali' }
    });
    
    fireEvent.change(screen.getByLabelText(/email/i), {
      target: { value: 'ahmed@example.com' }
    });
    
    fireEvent.submit(screen.getByRole('form'));
    
    // Assert
    await waitFor(() => {
      expect(onSubmit).toHaveBeenCalledWith({
        name: 'Ahmed Ali',
        email: 'ahmed@example.com'
      });
    });
  });
});
```

### Integration Testing

```python
# tests/integration/test_api.py
import pytest
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_create_lead_endpoint():
    """Test lead creation API endpoint."""
    # Arrange
    lead_data = {
        "name": "Ahmed Ali",
        "email": "ahmed@example.com",
        "phone": "+1234567890"
    }
    
    # Act
    response = client.post("/api/v1/leads", json=lead_data)
    
    # Assert
    assert response.status_code == 201
    data = response.json()
    assert data["name"] == lead_data["name"]
    assert "id" in data
```

### Performance Testing

```python
# tests/performance/test_scoring_performance.py
import asyncio
import time
from app.services.ai_scoring import AIScoringService

@pytest.mark.performance
async def test_scoring_performance():
    """Test that scoring meets performance requirements."""
    # Arrange
    service = AIScoringService()
    lead_data = create_test_lead_data()
    
    # Act
    start_time = time.time()
    result = await service.calculate_score_async(lead_data)
    execution_time = time.time() - start_time
    
    # Assert
    assert execution_time < 2.0, f"Scoring took {execution_time}s"
    assert result["score"] is not None
```

## ØªÙˆØ«ÙŠÙ‚ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª

### Commit Messages

Ù†ØªØ¨Ø¹ [Conventional Commits](https://www.conventionalcommits.org/):

```bash
# Examples
feat: add AI lead scoring feature
fix: resolve database connection timeout
docs: update API documentation for scoring endpoint
style: format Python code with black
refactor: simplify lead validation logic
test: add comprehensive tests for scoring service
chore: update dependencies
perf: optimize database queries for leads list
ci: add GitHub Actions workflow for testing
```

### Commit Message Structure

```
<type>[optional scope]: <description>

[optional body]

[optional footer(s)]
```

#### Types

- `feat`: New feature
- `fix`: Bug fix
- `docs`: Documentation changes
- `style`: Code style changes (formatting, etc.)
- `refactor`: Code refactoring
- `test`: Adding or modifying tests
- `chore`: Build process or auxiliary tool changes
- `perf`: Performance improvements
- `ci`: CI/CD changes

#### Examples

```bash
feat(ai-scoring): implement machine learning model integration

- Add TensorFlow model for lead scoring
- Implement real-time scoring endpoint
- Include confidence intervals in response
- Add comprehensive error handling

Closes #123

fix(database): resolve connection pool timeout issue

- Increase connection pool size
- Add connection retry logic
- Improve error messaging

Related to #456

docs(api): update scoring endpoint documentation

- Add request/response examples
- Include error code descriptions
- Add rate limiting information
```

### Changelog Entry

ÙÙŠ Ù…Ù„Ù `CHANGELOG.md`:

```markdown
## [Unreleased]

### Added
- AI-powered lead scoring feature (#123)
- Real-time scoring API endpoint (#124)
- Lead confidence intervals (#125)

### Changed
- Improved database query performance (#126)
- Updated API response format (#127)

### Fixed
- Resolved connection timeout issues (#128)
- Fixed memory leak in scoring service (#129)

### Deprecated
- Old scoring algorithm (will be removed in v2.0)
```

## Pull Request Process

### Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ PR

1. **ØªØ£ÙƒØ¯ Ù…Ù† Ø¥ØªÙ…Ø§Ù… Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª:**
   - Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ØªÙ…Ø±
   - Ø§Ù„ÙƒÙˆØ¯ ÙŠØªØ¨Ø¹ Ù…Ø¹Ø§ÙŠÙŠØ± style
   - Ø§Ù„ØªÙˆØ«ÙŠÙ‚ Ù…Ø­Ø¯Ø«
   - CHANGELOG Ù…Ø­Ø¯Ø«

2. **ØªØ­Ø¯ÙŠØ« main branch:**
   ```bash
   git checkout main
   git pull upstream main
   git checkout your-branch
   git rebase main
   ```

3. **ÙØ­Øµ Ù†Ù‡Ø§Ø¦ÙŠ:**
   ```bash
   # ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
   ./scripts/dev.sh test
   
   # ÙØ­Øµ quality
   ./scripts/dev.sh lint
   
   # ÙØ­Øµ security
   ./scripts/dev.sh security-check
   
   # build Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
   ./scripts/dev.sh build
   ```

### PR Template

Ø¹Ù†Ø¯ Ø¥Ù†Ø´Ø§Ø¡ PRØŒ Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ø§ template:

```markdown
## ÙˆØµÙ Ø§Ù„ØªØºÙŠÙŠØ±

ÙˆØµÙ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø®ØªØµØ± Ù„Ù„ØªØºÙŠÙŠØ± Ø§Ù„Ù…Ù‚ØªØ±Ø­.

## Ù†ÙˆØ¹ Ø§Ù„ØªØºÙŠÙŠØ±

- [ ] Bug fix (non-breaking change)
- [ ] New feature (non-breaking change)  
- [ ] Breaking change (fix or feature that would cause existing functionality to not work as expected)
- [ ] Documentation update
- [ ] Performance improvement
- [ ] Code refactoring

## ÙƒÙŠÙ ØªÙ… Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØºÙŠÙŠØ±ØŸ

- [ ] Unit tests pass locally
- [ ] Integration tests pass
- [ ] Manual testing completed
- [ ] Performance impact assessed

## Screenshots (Ø¥Ù† ÙˆØ¬Ø¯)

If this change affects the UI, add screenshots here.

## Checklist

- [ ] My code follows the style guidelines of this project
- [ ] I have performed a self-review of my own code
- [ ] I have commented my code, particularly in hard-to-understand areas
- [ ] I have made corresponding changes to the documentation
- [ ] My changes generate no new warnings
- [ ] I have added tests that prove my fix is effective or that my feature works
- [ ] New and existing unit tests pass locally with my changes
- [ ] Any dependent changes have been merged and published

## Related Issues

Closes #(issue_number)
```

### Ø¨Ø¹Ø¯ Ø¥Ù†Ø´Ø§Ø¡ PR

1. **ÙŠØ³Ù…Ø­ Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙƒÙˆØ¯ Ù…Ù† ÙØ±ÙŠÙ‚ Ø§Ù„ØªØ·ÙˆÙŠØ±**
2. **Ø³ÙŠØªÙ… ØªØ´ØºÙŠÙ„ CI checks ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹**
3. **ÙŠØ¬Ø¨ Ø­Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª ÙˆØ§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©**
4. **PR ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙ…Ø± Ø¨Ø¬Ù…ÙŠØ¹ checks Ù‚Ø¨Ù„ Ø§Ù„Ù€ merge**

## Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙƒÙˆØ¯

### Ù„Ù„Ù€ Author

#### Ù‚Ø¨Ù„ Ø¥Ù†Ø´Ø§Ø¡ PR

```bash
# ØªØ£ÙƒØ¯ Ù…Ù† clean history
git log --oneline -10

# ØªÙØ­Øµ Ø§Ù„Ù€ diff
git diff main

# ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ù€ tests
./scripts/dev.sh test-all

# ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„ØªÙˆØ«ÙŠÙ‚
./scripts/dev.sh check-docs
```

#### Ø¹Ù†Ø¯ Ø§Ù„Ø±Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª

- ÙƒÙ† Ù…Ù‡Ø°Ø¨ ÙˆÙ…Ù‡Ù†ÙŠ
- Ø§Ø´Ø±Ø­ Ù‚Ø±Ø§Ø±Ø§ØªÙƒ Ø¨ÙˆØ¶ÙˆØ­
- Ø§Ø·Ù„Ø¨ ØªÙˆØ¶ÙŠØ­ Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ØªØ£ÙƒØ¯
- Ù‚Ù… Ø¨Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø³Ø±Ø¹Ø©

### Ù„Ù„Ù€ Reviewer

#### Ù…Ø§ ÙŠØ¬Ø¨ ÙØ­ØµÙ‡

1. **Functionality**: Ù‡Ù„ Ø§Ù„ÙƒÙˆØ¯ ÙŠØ­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©ØŸ
2. **Code Quality**: Ù‡Ù„ Ø§Ù„ÙƒÙˆØ¯ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙÙ‡ÙˆÙ…ØŸ
3. **Security**: Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ù…Ø´Ø§ÙƒÙ„ Ø£Ù…Ù†ÙŠØ©ØŸ
4. **Performance**: Ù‡Ù„ Ø§Ù„ÙƒÙˆØ¯ performantØŸ
5. **Tests**: Ù‡Ù„ ÙŠÙˆØ¬Ø¯ tests Ù…Ù†Ø§Ø³Ø¨Ø©ØŸ
6. **Documentation**: Ù‡Ù„ Ø§Ù„ØªÙˆØ«ÙŠÙ‚ Ù…Ø­Ø¯Ø«ØŸ

#### Template Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©

```markdown
## Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙƒÙˆØ¯

### âœ… Ø§Ù„Ø¥ÙŠØ¬Ø§Ø¨ÙŠØ§Øª
- Code is well-structured and readable
- Good use of TypeScript types
- Comprehensive error handling

### ğŸ”„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
- Fix the database query performance issue in `getLeads()` function
- Add missing input validation for the `email` field
- Update the API documentation to include the new response format

### ğŸ’¡ Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù„Ù„ØªØ­Ø³ÙŠÙ†
- Consider using a caching layer for the scoring results
- The error messages could be more user-friendly
- Add loading states for better UX

### ğŸ“ Ø£Ø³Ø¦Ù„Ø©
- What's the expected throughput for the scoring endpoint?
- Should we add rate limiting for this feature?

### ğŸ§ª Testing
- [ ] All unit tests pass
- [ ] Integration tests pass  
- [ ] Manual testing completed
- [ ] Performance testing completed
```

## Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¬ÙˆØ¯Ø©

### Code Quality Metrics

#### Python

```python
# Ø­Ø¯ Ø£Ø¯Ù†Ù‰ 80% coverage
pytest --cov=app --cov-report=html

# Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯ Ù…Ø¹ flake8
flake8 app/ --max-complexity=10

# ÙØ­Øµ type hints Ù…Ø¹ mypy
mypy app/ --strict

# ÙØ­Øµ security Ù…Ø¹ bandit
bandit -r app/
```

#### JavaScript

```bash
# ESLint checks
npm run lint

# TypeScript checks
npx tsc --noEmit

# Test coverage
npm run test:coverage

# Bundle size
npm run analyze
```

### Performance Standards

```python
# API response time < 2 seconds
# Database queries < 100ms
# AI scoring < 3 seconds
# Frontend render time < 100ms

@pytest.mark.performance
async def test_api_performance():
    start_time = time.time()
    response = client.get("/api/v1/leads")
    response_time = time.time() - start_time
    
    assert response_time < 2.0, f"API response took {response_time}s"
```

### Security Requirements

```python
# âœ… Ø§Ø³ØªØ®Ø¯Ù… parameterized queries
query = "SELECT * FROM leads WHERE user_id = %s"
cursor.execute(query, (user_id,))

# âœ… validate Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
from pydantic import BaseModel, validator

class LeadCreate(BaseModel):
    name: str
    email: EmailStr
    phone: Optional[str]
    
    @validator('phone')
    def validate_phone(cls, v):
        if v and not re.match(r'^\+?[1-9]\d{1,14}$', v):
            raise ValueError('Invalid phone format')
        return v

# âœ… Ø§Ø³ØªØ®Ø¯Ù… authentication Ùˆ authorization
from fastapi.security import HTTPBearer
from jose import JWTError, jwt

async def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(HTTPBearer())):
    try:
        payload = jwt.decode(credentials.credentials, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: int = payload.get("sub")
        if user_id is None:
            raise HTTPException(status_code=401, detail="Invalid authentication credentials")
        return user_id
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid authentication credentials")
```

## Ù†ØµØ§Ø¦Ø­ Ù„Ù„Ù†Ø¬Ø§Ø­

### Ù„Ù„Ù…Ø¨ØªØ¯Ø¦ÙŠÙ†

1. **Ø§Ø¨Ø¯Ø£ Ø¨Ù…Ø´Ø§ÙƒÙ„ ØµØºÙŠØ±Ø©** - Ø§Ø®ØªØ± good first issue
2. **Ø§Ù‚Ø±Ø£ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯** - Ø§ÙÙ‡Ù… Ø§Ù„Ø¨Ù†ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©
3. **Ø§Ø³Ø£Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©** - Ù„Ø§ ØªØªØ±Ø¯Ø¯ ÙÙŠ Ø·Ø±Ø­ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
4. **ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø§Øª** - Ø§Ø³ØªÙØ¯ Ù…Ù† ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ÙŠÙ†

### Ù„Ù„Ù…Ø·ÙˆØ±ÙŠÙ† Ø§Ù„Ù…ØªÙ‚Ø¯Ù…ÙŠÙ†

1. **ÙƒÙ† mentor** - Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø·ÙˆØ±ÙŠÙ† Ø§Ù„Ø¬Ø¯Ø¯
2. **Ø­Ø§ÙØ¸ Ø¹Ù„Ù‰ standards** - ØªØ£ÙƒØ¯ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„ÙƒÙˆØ¯
3. **Ø´Ø§Ø±Ùƒ Ø§Ù„Ù…Ø¹Ø±ÙØ©** - Ø§ÙƒØªØ¨ Ø§Ù„ØªÙˆØ«ÙŠÙ‚ ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª
4. **ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª** - Ø§Ù‚ØªØ±Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª Ù„Ù„Ù€ workflow

## Ù…ÙˆØ§Ø±Ø¯ Ù…ÙÙŠØ¯Ø©

### Ø§Ù„ØªÙˆØ«ÙŠÙ‚

- [Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹](./quick-start.md)
- [Ø¯Ù„ÙŠÙ„ Ø³ÙŠØ± Ø§Ù„Ø¹Ù…Ù„](./workflow-guide.md)
- [Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª](./best-practices.md)
- [Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡](./troubleshooting.md)

### Tools

```bash
# Development tools
./scripts/setup.sh      # Setup development environment
./scripts/dev.sh        # Manage development services
./scripts/tools.sh      # Install development tools
./scripts/ide.sh        # Setup IDE configurations

# Quality checks
./scripts/test.sh       # Run all tests
./scripts/lint.sh       # Code quality checks
./scripts/security.sh   # Security checks
./scripts/performance.sh # Performance tests
```

### Community

- GitHub Discussions
- Discord Server
- Weekly Office Hours
- Monthly Community Call

## Ø´ÙƒØ± ÙˆØªÙ‚Ø¯ÙŠØ±

Ù†ØªÙ‚Ø¯Ù… Ø¨Ø§Ù„Ø´ÙƒØ± Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…ÙŠÙ† Ø§Ù„Ø°ÙŠÙ† ÙŠØ³Ø§Ø¹Ø¯ÙˆÙ† ÙÙŠ ØªØ·ÙˆÙŠØ± Saler. ÙƒÙ„ Ù…Ø³Ø§Ù‡Ù…Ø©ØŒ Ù…Ù‡Ù…Ø§ ÙƒØ§Ù†Øª ØµØºÙŠØ±Ø©ØŒ ØªØ³Ø§Ø¹Ø¯ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ù…Ù†ØªØ¬ Ø£ÙØ¶Ù„ Ù„Ù„Ø¬Ù…ÙŠØ¹.

---

ğŸ‰ **Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ ÙØ±ÙŠÙ‚ Saler!** Ù†ØªØ·Ù„Ø¹ Ù„Ø±Ø¤ÙŠØªÙƒ ÙˆÙ…Ø³Ø§Ù‡Ù…Ø§ØªÙƒ.