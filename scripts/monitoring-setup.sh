#!/bin/bash
#
# Ø³ÙƒØ±ÙŠØ¨Øª Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø´Ø§Ù…Ù„ - Comprehensive Monitoring Setup Script
# Ø¥Ø¹Ø¯Ø§Ø¯ ÙˆØªÙƒÙˆÙŠÙ† Ø¬Ù…ÙŠØ¹ Ù…ÙƒÙˆÙ†Ø§Øª Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ù„Ø´Ø±ÙƒØ© Ø³Ø§Ù„ÙŠØ±
#

set -euo pipefail

# Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ù„Ù„Ù†Øµ Ø§Ù„Ù…Ù„ÙˆÙ†
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
PROJECT_NAME="saler"
MONITORING_DIR="./monitoring"
LOGS_DIR="./logs"
SCRIPTS_DIR="./scripts"
GRAFANA_DIR="./grafana-dashboards"

# Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª
PROMETHEUS_VERSION="2.45.0"
GRAFANA_VERSION="10.0.0"
LOKI_VERSION="2.8.0"
PROMTAIL_VERSION="2.8.0"
ALERTMANAGER_VERSION="0.25.0"
NODE_EXPORTER_VERSION="1.6.0"

# Ø¯Ø§Ù„Ø© Ø·Ø¨Ø§Ø¹Ø© Ø±Ø³Ø§Ø¦Ù„ Ù…Ù„ÙˆÙ†Ø©
print_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

print_header() {
    echo -e "${PURPLE}========================================${NC}"
    echo -e "${PURPLE}$1${NC}"
    echo -e "${PURPLE}========================================${NC}"
}

# ÙØ­Øµ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª
check_requirements() {
    print_header "ÙØ­Øµ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"
    
    # ÙØ­Øµ Docker
    if ! command -v docker &> /dev/null; then
        print_error "Docker ØºÙŠØ± Ù…Ø«Ø¨Øª. ÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØª Docker Ø£ÙˆÙ„Ø§Ù‹."
        exit 1
    fi
    print_success "Docker Ù…ØªÙˆÙØ±: $(docker --version)"
    
    # ÙØ­Øµ Docker Compose
    if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null 2>&1; then
        print_error "Docker Compose ØºÙŠØ± Ù…ØªÙˆÙØ±. ÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØª Docker Compose Ø£ÙˆÙ„Ø§Ù‹."
        exit 1
    fi
    print_success "Docker Compose Ù…ØªÙˆÙØ±"
    
    # ÙØ­Øµ curl
    if ! command -v curl &> /dev/null; then
        print_warning "curl ØºÙŠØ± Ù…ØªÙˆÙØ±. Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡..."
        sudo apt-get update && sudo apt-get install -y curl
    fi
    
    # ÙØ­Øµ jq
    if ! command -v jq &> /dev/null; then
        print_warning "jq ØºÙŠØ± Ù…ØªÙˆÙØ±. Ø³ÙŠØªÙ… ØªØ«Ø¨ÙŠØªÙ‡..."
        sudo apt-get update && sudo apt-get install -y jq
    fi
    
    # ÙØ­Øµ Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©
    available_space=$(df -BG . | awk 'NR==2 {print $4}' | sed 's/G//')
    if [ "$available_space" -lt 10 ]; then
        print_error "Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù‚Ø±Øµ ØºÙŠØ± ÙƒØ§ÙÙŠØ©. Ù…Ø·Ù„ÙˆØ¨ Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ù„ 10GB."
        exit 1
    fi
    print_success "Ø§Ù„Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù…ØªØ§Ø­Ø©: ${available_space}GB"
}

# Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
create_directory_structure() {
    print_header "Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª"
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    mkdir -p $MONITORING_DIR
    mkdir -p $LOGS_DIR/{application,system,security,analytics}
    mkdir -p $SCRIPTS_DIR
    mkdir -p $GRAFANA_DIR
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ†
    mkdir -p $MONITORING_DIR/{prometheus,grafana,loki,alertmanager,config}
    mkdir -p $MONITORING_DIR/exporters/{node,redis,postgres,custom}
    mkdir -p $MONITORING_DIR/data/{prometheus,grafana,loki,alertmanager}
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
    mkdir -p backups/{configs,data,logs}
    
    print_success "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‡ÙŠÙƒÙ„ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª Ø¨Ù†Ø¬Ø§Ø­"
}

# ØªØ­Ù…ÙŠÙ„ ÙˆØªØ­Ø¶ÙŠØ± Ø§Ù„Ù…Ù„ÙØ§Øª
download_files() {
    print_header "ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ† ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"
    
    cd $MONITORING_DIR
    
    # ØªØ­Ù…ÙŠÙ„ Prometheus
    if [ ! -f "prometheus-${PROMETHEUS_VERSION}.linux-amd64.tar.gz" ]; then
        print_info "ØªØ­Ù…ÙŠÙ„ Prometheus..."
        wget https://github.com/prometheus/prometheus/releases/download/v${PROMETHEUS_VERSION}/prometheus-${PROMETHEUS_VERSION}.linux-amd64.tar.gz
        tar xzf prometheus-${PROMETHEUS_VERSION}.linux-amd64.tar.gz
        mv prometheus-${PROMETHEUS_VERSION}.linux-amd64 prometheus
    fi
    
    # ØªØ­Ù…ÙŠÙ„ Node Exporter
    if [ ! -f "node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz" ]; then
        print_info "ØªØ­Ù…ÙŠÙ„ Node Exporter..."
        wget https://github.com/prometheus/node_exporter/releases/download/v${NODE_EXPORTER_VERSION}/node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz
        tar xzf node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64.tar.gz
        mv node_exporter-${NODE_EXPORTER_VERSION}.linux-amd64 node_exporter
    fi
    
    # ØªØ­Ù…ÙŠÙ„ Alertmanager
    if [ ! -f "alertmanager-${ALERTMANAGER_VERSION}.linux-amd64.tar.gz" ]; then
        print_info "ØªØ­Ù…ÙŠÙ„ Alertmanager..."
        wget https://github.com/prometheus/alertmanager/releases/download/v${ALERTMANAGER_VERSION}/alertmanager-${ALERTMANAGER_VERSION}.linux-amd64.tar.gz
        tar xzf alertmanager-${ALERTMANAGER_VERSION}.linux-amd64.tar.gz
        mv alertmanager-${ALERTMANAGER_VERSION}.linux-amd64 alertmanager
    fi
    
    cd - > /dev/null
    print_success "ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª"
}

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Docker Compose
create_docker_compose() {
    print_header "Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Docker Compose"
    
    cat > docker-compose.monitoring.yml << 'EOF'
version: '3.8'

services:
  # Prometheus - Ù†Ø¸Ø§Ù… Ø¬Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
  prometheus:
    image: prom/prometheus:v2.45.0
    container_name: saler-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus:/etc/prometheus
      - ./monitoring/data/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    restart: unless-stopped
    networks:
      - monitoring

  # Grafana - Ù†Ø¸Ø§Ù… Ø¹Ø±Ø¶ Ø§Ù„Ù„ÙˆØ­Ø§Øª
  grafana:
    image: grafana/grafana:10.0.0
    container_name: saler-grafana
    ports:
      - "3000:3000"
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - ./monitoring/data/grafana:/var/lib/grafana
      - ./grafana-dashboards:/var/lib/grafana/dashboards
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_INSTALL_PLUGINS=grafana-clock-panel,grafana-simple-json-datasource
    restart: unless-stopped
    networks:
      - monitoring

  # Loki - Ù†Ø¸Ø§Ù… ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª
  loki:
    image: grafana/loki:2.8.0
    container_name: saler-loki
    ports:
      - "3100:3100"
    volumes:
      - ./monitoring/loki/loki-config.yml:/etc/loki/local-config.yaml
      - ./monitoring/data/loki:/loki
    command: -config.file=/etc/loki/local-config.yaml
    restart: unless-stopped
    networks:
      - monitoring

  # Promtail - ÙˆÙƒÙŠÙ„ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø³Ø¬Ù„Ø§Øª Ø¥Ù„Ù‰ Loki
  promtail:
    image: grafana/promtail:2.8.0
    container_name: saler-promtail
    volumes:
      - ./monitoring/loki/promtail-config.yml:/etc/promtail/config.yml
      - /var/log:/var/log:ro
      - ./logs:/var/log/saler:ro
    command: -config.file=/etc/promtail/config.yml
    restart: unless-stopped
    networks:
      - monitoring

  # Alertmanager - Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
  alertmanager:
    image: prom/alertmanager:v0.25.0
    container_name: saler-alertmanager
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager/alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - ./monitoring/data/alertmanager:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
      - '--web.external-url=http://localhost:9093'
    restart: unless-stopped
    networks:
      - monitoring

  # Redis Exporter - Ù…Ø±Ø§Ù‚Ø¨Ø© Redis
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: saler-redis-exporter
    environment:
      - REDIS_ADDR=redis://redis:6379
    ports:
      - "9121:9121"
    restart: unless-stopped
    networks:
      - monitoring
    depends_on:
      - redis

  # Postgres Exporter - Ù…Ø±Ø§Ù‚Ø¨Ø© PostgreSQL
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: saler-postgres-exporter
    environment:
      - DATA_SOURCE_NAME=postgresql://user:pass@postgres:5432/db?sslmode=disable
    ports:
      - "9187:9187"
    restart: unless-stopped
    networks:
      - monitoring

  # Ù…Ø«Ø§Ù„ Redis Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
  redis:
    image: redis:alpine
    container_name: saler-redis
    ports:
      - "6379:6379"
    restart: unless-stopped
    networks:
      - monitoring

  # Ù…Ø«Ø§Ù„ PostgreSQL Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©
  postgres:
    image: postgres:13
    container_name: saler-postgres
    environment:
      - POSTGRES_DB=saler
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=pass
    ports:
      - "5432:5432"
    volumes:
      - ./monitoring/data/postgres:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - monitoring

networks:
  monitoring:
    driver: bridge

volumes:
  prometheus_data:
  grafana_data:
  loki_data:
  alertmanager_data:
EOF

    print_success "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Docker Compose"
}

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯ Prometheus
create_prometheus_config() {
    print_header "Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯ Prometheus"
    
    cat > $MONITORING_DIR/prometheus/prometheus.yml << 'EOF'
# ØªÙƒÙˆÙŠÙ† Prometheus Ù„Ø´Ø±ÙƒØ© Ø³Ø§Ù„ÙŠØ±

global:
  scrape_interval: 15s
  evaluation_interval: 15s
  external_labels:
    cluster: 'saler-cluster'
    environment: 'production'

# Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„
rule_files:
  - "alert_rules.yml"

# ØªÙƒÙˆÙŠÙ† Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
alerting:
  alertmanagers:
    - static_configs:
        - targets:
          - alertmanager:9093

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ­Ù…ÙŠÙ„
scrape_configs:
  # Ù…Ø±Ø§Ù‚Ø¨Ø© Prometheus Ù†ÙØ³Ù‡
  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']

  # Ù…Ø±Ø§Ù‚Ø¨Ø© Node Exporter
  - job_name: 'node-exporter'
    static_configs:
      - targets: ['node-exporter:9100']
    scrape_interval: 5s
    metrics_path: /metrics

  # Ù…Ø±Ø§Ù‚Ø¨Ø© Redis
  - job_name: 'redis'
    static_configs:
      - targets: ['redis-exporter:9121']
    scrape_interval: 10s

  # Ù…Ø±Ø§Ù‚Ø¨Ø© PostgreSQL
  - job_name: 'postgresql'
    static_configs:
      - targets: ['postgres-exporter:9187']
    scrape_interval: 30s

  # Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ - Ø§Ø³ØªØ¨Ø¯Ù„ Ù‡Ø°Ø§ Ø¨Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙØ¹Ù„ÙŠ
  - job_name: 'saler-app'
    static_configs:
      - targets: ['app:8080']
    metrics_path: /metrics
    scrape_interval: 15s

  # Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…Ø®ØµØµØ© Ù„Ù„ØªØ·Ø¨ÙŠÙ‚
  - job_name: 'saler-custom'
    static_configs:
      - targets: ['localhost:8080']
    metrics_path: /custom-metrics
    scrape_interval: 30s
    params:
      format: ['prometheus']

  # Ù…Ø±Ø§Ù‚Ø¨Ø© Ø®Ø¯Ù…Ø§Øª Kubernetes (Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªÙˆÙØ±Ø©)
  - job_name: 'kubernetes-apiservers'
    kubernetes_sd_configs:
      - role: endpoints
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
      - source_labels: [__meta_kubernetes_namespace, __meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
        action: keep
        regex: default;kubernetes;https

  # Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª ÙÙŠ Kubernetes
  - job_name: 'kubernetes-nodes'
    kubernetes_sd_configs:
      - role: node
    scheme: https
    tls_config:
      ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
    bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
    relabel_configs:
      - action: labelmap
        regex: __meta_kubernetes_node_label_(.+)
      - target_label: __address__
        replacement: kubernetes.default.svc:443
      - source_labels: [__meta_kubernetes_node_name]
        regex: (.+)
        target_label: __metrics_path__
        replacement: /api/v1/nodes/${1}/proxy/metrics

  # Ù…Ø±Ø§Ù‚Ø¨Ø© Pods ÙÙŠ Kubernetes
  - job_name: 'kubernetes-pods'
    kubernetes_sd_configs:
      - role: pod
    relabel_configs:
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_pod_name]
        action: replace
        target_label: kubernetes_pod_name

  # Ù…Ø±Ø§Ù‚Ø¨Ø© Ø®Ø¯Ù…Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª
  - job_name: 'saler-services'
    kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
            - saler-production
            - saler-staging
    relabel_configs:
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
        action: keep
        regex: true
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scheme]
        action: replace
        target_label: __scheme__
        regex: (https?)
      - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_service_label_(.+)
      - source_labels: [__meta_kubernetes_namespace]
        action: replace
        target_label: kubernetes_namespace
      - source_labels: [__meta_kubernetes_service_name]
        action: replace
        target_label: kubernetes_name
EOF

    # Ø¥Ù†Ø´Ø§Ø¡ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
    cat > $MONITORING_DIR/prometheus/alert_rules.yml << 'EOF'
# Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ù„Ø´Ø±ÙƒØ© Ø³Ø§Ù„ÙŠØ±

groups:
- name: saler-system.rules
  rules:
  # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
  - alert: InstanceDown
    expr: up == 0
    for: 1m
    labels:
      severity: critical
      service: "{{ $labels.job }}"
    annotations:
      summary: "Instance {{ $labels.instance }} is down"
      description: "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 1 minute."

  - alert: HighCPUUsage
    expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
    for: 5m
    labels:
      severity: warning
      service: node
    annotations:
      summary: "High CPU usage on {{ $labels.instance }}"
      description: "CPU usage is above 80% for more than 5 minutes on {{ $labels.instance }}."

  - alert: HighMemoryUsage
    expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
    for: 5m
    labels:
      severity: warning
      service: node
    annotations:
      summary: "High memory usage on {{ $labels.instance }}"
      description: "Memory usage is above 85% for more than 5 minutes on {{ $labels.instance }}."

  - alert: DiskSpaceLow
    expr: (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes) * 100 < 10
    for: 5m
    labels:
      severity: critical
      service: node
    annotations:
      summary: "Low disk space on {{ $labels.instance }}"
      description: "Disk space is below 10% on {{ $labels.instance }} ({{ $labels.mountpoint }})."

- name: saler-application.rules
  rules:
  # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
  - alert: HighErrorRate
    expr: rate(http_requests_total{status=~"5.."}[5m]) / rate(http_requests_total[5m]) * 100 > 5
    for: 2m
    labels:
      severity: critical
      service: saler-app
    annotations:
      summary: "High error rate on {{ $labels.instance }}"
      description: "Error rate is above 5% for more than 2 minutes on {{ $labels.instance }}."

  - alert: HighResponseTime
    expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket[5m])) by (le, instance)) > 0.5
    for: 5m
    labels:
      severity: warning
      service: saler-app
    annotations:
      summary: "High response time on {{ $labels.instance }}"
      description: "95th percentile response time is above 500ms for more than 5 minutes on {{ $labels.instance }}."

  - alert: DatabaseConnectionsHigh
    expr: pg_stat_activity_count > 80
    for: 5m
    labels:
      severity: warning
      service: postgres
    annotations:
      summary: "High database connections"
      description: "Database has more than 80 active connections for more than 5 minutes."

  - alert: RedisMemoryUsageHigh
    expr: redis_memory_used_bytes / redis_memory_max_bytes * 100 > 90
    for: 5m
    labels:
      severity: warning
      service: redis
    annotations:
      summary: "High Redis memory usage"
      description: "Redis memory usage is above 90% for more than 5 minutes."

- name: saler-business.rules
  rules:
  # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ø£Ø¹Ù…Ø§Ù„
  - alert: LowConversionRate
    expr: sum(rate(conversions_total[1h])) / sum(rate(visits_total[1h])) * 100 < 2
    for: 10m
    labels:
      severity: warning
      service: business
    annotations:
      summary: "Low conversion rate"
      description: "Conversion rate is below 2% for more than 10 minutes."

  - alert: RevenueDrop
    expr: sum(rate(order_revenue_total[1h])) < avg_over_time(sum(rate(order_revenue_total[1h]))[24h:1h]) * 0.5
    for: 30m
    labels:
      severity: critical
      service: business
    annotations:
      summary: "Significant revenue drop"
      description: "Revenue has dropped by more than 50% compared to 24-hour average."
EOF

    print_success "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Prometheus"
}

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯ Alertmanager
create_alertmanager_config() {
    print_header "Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯ Alertmanager"
    
    cat > $MONITORING_DIR/alertmanager/alertmanager.yml << 'EOF'
# ØªÙƒÙˆÙŠÙ† Alertmanager Ù„Ø´Ø±ÙƒØ© Ø³Ø§Ù„ÙŠØ±

global:
  smtp_smarthost: 'localhost:587'
  smtp_from: 'alerts@saler.com'
  smtp_auth_username: 'alerts@saler.com'
  smtp_auth_password: 'password'
  resolve_timeout: 5m

# Ù‚ÙˆØ§Ù„Ø¨ Ø§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„ØªÙˆØ¬ÙŠÙ‡
route:
  group_by: ['alertname', 'instance']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h
  receiver: 'default'
  routes:
  # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø­Ø±Ø¬Ø©
  - match:
      severity: critical
    receiver: 'critical-alerts'
    group_wait: 5s
    repeat_interval: 5m
  
  # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
  - match:
      service: node
    receiver: 'system-alerts'
    group_interval: 5m
    repeat_interval: 30m
  
  # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
  - match:
      service: saler-app
    receiver: 'app-alerts'
    group_interval: 2m
    repeat_interval: 15m
  
  # ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ø£Ø¹Ù…Ø§Ù„
  - match:
      service: business
    receiver: 'business-alerts'
    group_interval: 15m
    repeat_interval: 2h

# Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
receivers:
- name: 'default'
  email_configs:
  - to: 'ops@saler.com'
    subject: '[SALER] {{ .GroupLabels.alertname }}'
    body: |
      {{ range .Alerts }}
      Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡: {{ .Annotations.summary }}
      Ø§Ù„ÙˆØµÙ: {{ .Annotations.description }}
      Ø§Ù„ÙˆÙ‚Øª: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
      Ø§Ù„Ø´Ø¯Ø©: {{ .Labels.severity }}
      {{ end }}

- name: 'critical-alerts'
  email_configs:
  - to: 'oncall@saler.com,ops@saler.com'
    subject: '[CRITICAL] {{ .GroupLabels.alertname }}'
    body: |
      ØªÙ†Ø¨ÙŠÙ‡ Ø­Ø±Ø¬ - ÙŠØªØ·Ù„Ø¨ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª ÙÙˆØ±ÙŠØ©
      
      {{ range .Alerts }}
      Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡: {{ .Annotations.summary }}
      Ø§Ù„ÙˆØµÙ: {{ .Annotations.description }}
      Ø§Ù„ÙˆÙ‚Øª: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
      Ø§Ù„Ø´Ø¯Ø©: {{ .Labels.severity }}
      Ø§Ù„Ø®Ø§Ø¯Ù…: {{ .Labels.instance }}
      {{ end }}
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
    channel: '#critical-alerts'
    title: 'ØªÙ†Ø¨ÙŠÙ‡ Ø­Ø±Ø¬ - {{ .GroupLabels.alertname }}'
    text: '{{ range .Alerts }}â€¢ {{ .Annotations.summary }}{{ end }}'

- name: 'system-alerts'
  email_configs:
  - to: 'ops@saler.com'
    subject: '[SYSTEM] {{ .GroupLabels.alertname }}'
    body: |
      ØªÙ†Ø¨ÙŠÙ‡ Ù†Ø¸Ø§Ù…
      
      {{ range .Alerts }}
      Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡: {{ .Annotations.summary }}
      Ø§Ù„ÙˆØµÙ: {{ .Annotations.description }}
      Ø§Ù„ÙˆÙ‚Øª: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
      Ø§Ù„Ø®Ø§Ø¯Ù…: {{ .Labels.instance }}
      {{ end }}

- name: 'app-alerts'
  email_configs:
  - to: 'dev-team@saler.com,ops@saler.com'
    subject: '[APP] {{ .GroupLabels.alertname }}'
    body: |
      ØªÙ†Ø¨ÙŠÙ‡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
      
      {{ range .Alerts }}
      Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡: {{ .Annotations.summary }}
      Ø§Ù„ÙˆØµÙ: {{ .Annotations.description }}
      Ø§Ù„ÙˆÙ‚Øª: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
      Ø§Ù„Ø®Ø¯Ù…Ø©: {{ .Labels.service }}
      {{ end }}
  slack_configs:
  - api_url: 'https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK'
    channel: '#dev-alerts'
    title: 'ØªÙ†Ø¨ÙŠÙ‡ ØªØ·Ø¨ÙŠÙ‚ - {{ .GroupLabels.alertname }}'
    text: '{{ range .Alerts }}â€¢ {{ .Annotations.summary }}{{ end }}'

- name: 'business-alerts'
  email_configs:
  - to: 'business@saler.com,management@saler.com'
    subject: '[BUSINESS] {{ .GroupLabels.alertname }}'
    body: |
      ØªÙ†Ø¨ÙŠÙ‡ Ø£Ø¹Ù…Ø§Ù„
      
      {{ range .Alerts }}
      Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡: {{ .Annotations.summary }}
      Ø§Ù„ÙˆØµÙ: {{ .Annotations.description }}
      Ø§Ù„ÙˆÙ‚Øª: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
      Ø§Ù„Ø®Ø¯Ù…Ø©: {{ .Labels.service }}
      {{ end }}

# Ù‚ÙˆØ§Ø¹Ø¯ ÙƒØªÙ… Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª
inhibit_rules:
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']
EOF

    print_success "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Alertmanager"
}

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯ Loki
create_loki_config() {
    print_header "Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¥Ø¹Ø¯Ø§Ø¯ Loki"
    
    cat > $MONITORING_DIR/loki/loki-config.yml << 'EOF'
# ØªÙƒÙˆÙŠÙ† Loki Ù„Ø´Ø±ÙƒØ© Ø³Ø§Ù„ÙŠØ±

auth_enabled: false

server:
  http_listen_port: 3100

common:
  path_prefix: /loki
  storage:
    filesystem:
      chunks_directory: /loki/chunks
      rules_directory: /loki/rules
  replication_factor: 1
  ring:
    instance_addr: 127.0.0.1
    kvstore:
      store: inmemory

query_range:
  results_cache:
    cache:
      embedded_cache:
        enabled: true
        max_size_mb: 100

schema_config:
  configs:
    - from: 2020-10-24
      store: boltdb-shipper
      object_store: filesystem
      schema: v11
      index:
        prefix: index_
        period: 24h

ruler:
  alertmanager_url: http://alertmanager:9093

analytics:
  reporting_enabled: false
EOF

    # Ø¥Ø¹Ø¯Ø§Ø¯ Promtail
    cat > $MONITORING_DIR/loki/promtail-config.yml << 'EOF'
# ØªÙƒÙˆÙŠÙ† Promtail Ù„Ø´Ø±ÙƒØ© Ø³Ø§Ù„ÙŠØ±

server:
  http_listen_port: 9080
  grpc_listen_port: 0

positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://loki:3100/loki/api/v1/push

scrape_configs:
  # Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
  - job_name: system
    static_configs:
      - targets:
          - localhost
        labels:
          job: syslog
          __path__: /var/log/syslog
    pipeline_stages:
      - json:
          expressions:
            output: log
            timestamp: time
      - timestamp:
          source: timestamp
          format: RFC3339
      - labels:
          timestamp:

  # Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª
  - job_name: saler-app
    static_configs:
      - targets:
          - localhost
        labels:
          job: saler-app
          __path__: /var/log/saler/*.log
    pipeline_stages:
      - json:
          expressions:
            level: level
            service: service
            message: msg
      - labels:
          level:
          service:
      - timestamp:
          format: RFC3339
          source: time
      - output:
          source: message

  # Ø³Ø¬Ù„Ø§Øª Nginx
  - job_name: nginx
    static_configs:
      - targets:
          - localhost
        labels:
          job: nginx
          __path__: /var/log/nginx/*.log
    pipeline_stages:
      - regex:
          expression: '^(?P<remote_addr>[\w\.]+) - (?P<remote_user>.*?) \[(?P<time_local>.*?)\] "(?P<method>.*?) (?P<request>.*?) (?P<protocol>.*?)" (?P<status>[\d]+) (?P<body_bytes_sent>[\d]+) "(?P<http_referer>.*?)" "(?P<http_user_agent>.*?)"'
      - labels:
          method:
          status:
          remote_addr:
      - timestamp:
          format: '02/Jan/2006:15:04:05 -0700'
          source: time_local

  # Ø³Ø¬Ù„Ø§Øª Docker
  - job_name: docker
    docker_sd_configs:
      - host: unix:///var/run/docker.sock
        refresh_interval: 5s
    relabel_configs:
      - source_labels: ['__meta_docker_container_name']
        target_label: 'container'
      - source_labels: ['__meta_docker_container_label_logging']
        action: keep
        regex: 'promtail'
    pipeline_stages:
      - json:
          expressions:
            output: log
            stream: stream
      - labels:
          stream:
          container:

  # Ø³Ø¬Ù„Ø§Øª Kubernetes
  - job_name: kubernetes
    kubernetes_sd_configs:
      - role: pod
        namespaces:
          names:
            - saler-production
            - saler-staging
    relabel_configs:
      - source_labels: ['__meta_kubernetes_pod_annotation_prometheus_io_scrape']
        action: keep
        regex: true
      - source_labels: ['__meta_kubernetes_pod_annotation_prometheus_io_path']
        action: replace
        target_label: __metrics_path__
        regex: (.+)
      - source_labels: ['__address__', '__meta_kubernetes_pod_annotation_prometheus_io_port']
        action: replace
        regex: ([^:]+)(?::\d+)?;(\d+)
        replacement: $1:$2
        target_label: __address__
      - action: labelmap
        regex: __meta_kubernetes_pod_label_(.+)
      - source_labels: ['__meta_kubernetes_namespace']
        action: replace
        target_label: kubernetes_namespace
      - source_labels: ['__meta_kubernetes_pod_name']
        action: replace
        target_label: kubernetes_pod_name
    pipeline_stages:
      - json:
          expressions:
            output: log
            stream: stream
      - labels:
          stream:
      - output:
          source: output
EOF

    print_success "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Loki"
}

# Ø¥Ø¹Ø¯Ø§Ø¯ Grafana
setup_grafana() {
    print_header "Ø¥Ø¹Ø¯Ø§Ø¯ Grafana"
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    mkdir -p $MONITORING_DIR/grafana/provisioning/{datasources,dashboards}
    
    cat > $MONITORING_DIR/grafana/provisioning/datasources/prometheus.yml << 'EOF'
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true

  - name: Loki
    type: loki
    access: proxy
    url: http://loki:3100
    editable: true
    jsonData:
      maxLines: 1000

  - name: Alertmanager
    type: alertmanager
    access: proxy
    url: http://alertmanager:9093
    editable: true
EOF

    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ÙˆØ­Ø§Øª
    cat > $MONITORING_DIR/grafana/provisioning/dashboards/dashboard.yml << 'EOF'
apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /var/lib/grafana/dashboards
EOF

    # Ù†Ø³Ø® Ù„ÙˆØ­Ø§Øª Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
    cp -r ../grafana-dashboards/* $MONITORING_DIR/grafana/provisioning/dashboards/
    
    print_success "ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Grafana"
}

# Ø¨Ø¯Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
start_services() {
    print_header "Ø¨Ø¯Ø¡ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©"
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø´Ø¨ÙƒØ© Docker Ø¥Ø°Ø§ Ù„Ù… ØªÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø©
    docker network ls | grep -q monitoring || docker network create monitoring
    
    # Ø¨Ù†Ø§Ø¡ ÙˆØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
    docker-compose -f docker-compose.monitoring.yml up -d
    
    print_info "Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø¯Ø¡ Ø§Ù„Ø®Ø¯Ù…Ø§Øª..."
    sleep 30
    
    # ÙØ­Øµ Ø­Ø§Ù„Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª
    if docker-compose -f docker-compose.monitoring.yml ps | grep -q "Up"; then
        print_success "ØªÙ… Ø¨Ø¯Ø¡ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø¨Ù†Ø¬Ø§Ø­"
        
        echo ""
        print_info "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:"
        echo "  â€¢ Prometheus: http://localhost:9090"
        echo "  â€¢ Grafana: http://localhost:3000 (admin/admin123)"
        echo "  â€¢ Alertmanager: http://localhost:9093"
        echo "  â€¢ Loki: http://localhost:3100"
        echo ""
    else
        print_error "ÙØ´Ù„ ÙÙŠ Ø¨Ø¯Ø¡ Ø¨Ø¹Ø¶ Ø§Ù„Ø®Ø¯Ù…Ø§Øª. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª:"
        docker-compose -f docker-compose.monitoring.yml logs
        exit 1
    fi
}

# Ø¥Ø¹Ø¯Ø§Ø¯ Node Exporter
setup_node_exporter() {
    print_header "Ø¥Ø¹Ø¯Ø§Ø¯ Node Exporter"
    
    # ØªØ´ØºÙŠÙ„ Node Exporter Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø­Ù„ÙŠ
    cd $MONITORING_DIR/node_exporter
    ./node_exporter --web.listen-address=":9100" &
    cd ../..
    
    print_success "ØªÙ… ØªØ´ØºÙŠÙ„ Node Exporter Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù†ÙØ° 9100"
}

# Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø¯Ù…Ø§Øª
create_stop_script() {
    print_header "Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø¯Ù…Ø§Øª"
    
    cat > stop-monitoring.sh << 'EOF'
#!/bin/bash
# Ø³ÙƒØ±ÙŠØ¨Øª Ø¥ÙŠÙ‚Ø§Ù Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©

echo "Ø¥ÙŠÙ‚Ø§Ù Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©..."

# Ø¥ÙŠÙ‚Ø§Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø­Ø§ÙˆÙŠØ§Øª
docker-compose -f docker-compose.monitoring.yml down

# Ø¥ÙŠÙ‚Ø§Ù Node Exporter
pkill -f node_exporter

# Ø¥ÙŠÙ‚Ø§Ù Prometheus (Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¹Ù…Ù„ Ù…Ø­Ù„ÙŠØ§Ù‹)
pkill -f prometheus

echo "ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø¬Ù…ÙŠØ¹ Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©"
EOF

    chmod +x stop-monitoring.sh
    print_success "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù"
}

# Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
create_backup_script() {
    print_header "Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"
    
    cat > backup-monitoring.sh << 'EOF'
#!/bin/bash
# Ø³ÙƒØ±ÙŠØ¨Øª Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©

BACKUP_DIR="./backups/monitoring-$(date +%Y%m%d_%H%M%S)"
mkdir -p $BACKUP_DIR

echo "Ø¨Ø¯Ø¡ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¥Ù„Ù‰: $BACKUP_DIR"

# Ù†Ø³Ø® Ø¨ÙŠØ§Ù†Ø§Øª Prometheus
docker exec saler-prometheus tar czf - /prometheus > $BACKUP_DIR/prometheus_data.tar.gz

# Ù†Ø³Ø® Ø¨ÙŠØ§Ù†Ø§Øª Grafana
docker exec saler-grafana tar czf - /var/lib/grafana > $BACKUP_DIR/grafana_data.tar.gz

# Ù†Ø³Ø® Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Loki
docker exec saler-loki tar czf - /loki > $BACKUP_DIR/loki_data.tar.gz

# Ù†Ø³Ø® Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Alertmanager
docker exec saler-alertmanager tar czf - /alertmanager > $BACKUP_DIR/alertmanager_data.tar.gz

# Ù†Ø³Ø® Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ†
cp -r monitoring/prometheus $BACKUP_DIR/
cp -r monitoring/alertmanager $BACKUP_DIR/
cp -r monitoring/loki $BACKUP_DIR/
cp docker-compose.monitoring.yml $BACKUP_DIR/

echo "ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"
echo "Ø­Ø¬Ù… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: $(du -sh $BACKUP_DIR | cut -f1)"
EOF

    chmod +x backup-monitoring.sh
    print_success "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ"
}

# Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©
create_restore_script() {
    print_header "Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©"
    
    cat > restore-monitoring.sh << 'EOF'
#!/bin/bash
# Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©

if [ -z "$1" ]; then
    echo "Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…: $0 <Ù…Ø¬Ù„Ø¯_Ø§Ù„Ù†Ø³Ø®_Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ>"
    exit 1
fi

BACKUP_DIR=$1

if [ ! -d "$BACKUP_DIR" ]; then
    echo "Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: $BACKUP_DIR"
    exit 1
fi

echo "Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù…Ù†: $BACKUP_DIR"

# Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø®Ø¯Ù…Ø§Øª
docker-compose -f docker-compose.monitoring.yml down

# Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Prometheus
docker run --rm -v saler_prometheus_data:/prometheus -v $BACKUP_DIR:/backup alpine tar xzf /backup/prometheus_data.tar.gz -C /

# Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Grafana
docker run --rm -v saler_grafana_data:/grafana -v $BACKUP_DIR:/backup alpine tar xzf /backup/grafana_data.tar.gz -C /

# Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Loki
docker run --rm -v saler_loki_data:/loki -v $BACKUP_DIR:/backup alpine tar xzf /backup/loki_data.tar.gz -C /

# Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Alertmanager
docker run --rm -v saler_alertmanager_data:/alertmanager -v $BACKUP_DIR:/backup alpine tar xzf /backup/alertmanager_data.tar.gz -C /

# Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙƒÙˆÙŠÙ†
cp -r $BACKUP_DIR/prometheus monitoring/
cp -r $BACKUP_DIR/alertmanager monitoring/
cp -r $BACKUP_DIR/loki monitoring/
cp $BACKUP_DIR/docker-compose.monitoring.yml ./

# Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
docker-compose -f docker-compose.monitoring.yml up -d

echo "ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©"
EOF

    chmod +x restore-monitoring.sh
    print_success "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©"
}

# Ø¹Ø±Ø¶ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ«Ø¨ÙŠØª
show_summary() {
    print_header "Ù…Ù„Ø®Øµ Ø§Ù„ØªØ«Ø¨ÙŠØª"
    
    echo ""
    print_success "ØªÙ… Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø¨Ù†Ø¬Ø§Ø­!"
    echo ""
    echo "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:"
    echo "  ğŸ” Prometheus (Ø¬Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³): http://localhost:9090"
    echo "  ğŸ“Š Grafana (Ø¹Ø±Ø¶ Ø§Ù„Ù„ÙˆØ­Ø§Øª): http://localhost:3000"
    echo "  ğŸ”” Alertmanager (Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª): http://localhost:9093"
    echo "  ğŸ“ Loki (ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª): http://localhost:3100"
    echo ""
    echo "Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©:"
    echo "  Grafana: admin / admin123"
    echo ""
    echo "Ù…Ù„ÙØ§Øª Ù…ÙÙŠØ¯Ø©:"
    echo "  â€¢ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø¥ÙŠÙ‚Ø§Ù: ./stop-monitoring.sh"
    echo "  â€¢ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: ./backup-monitoring.sh"
    echo "  â€¢ Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©: ./restore-monitoring.sh <Ù…Ø¬Ù„Ø¯_Ø§Ù„Ù†Ø³Ø®_Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ>"
    echo ""
    echo "Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©:"
    echo "  â€¢ Ø¹Ø±Ø¶ Ø§Ù„Ø³Ø¬Ù„Ø§Øª: docker-compose -f docker-compose.monitoring.yml logs -f"
    echo "  â€¢ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø®Ø¯Ù…Ø©: docker-compose -f docker-compose.monitoring.yml restart <service>"
    echo "  â€¢ Ø¥ÙŠÙ‚Ø§Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø®Ø¯Ù…Ø§Øª: ./stop-monitoring.sh"
    echo ""
}

# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
main() {
    print_header "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨Ùƒ ÙÙŠ Ù†Ø¸Ø§Ù… Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ø´Ø±ÙƒØ© Ø³Ø§Ù„ÙŠØ±"
    echo "Ù‡Ø°Ø§ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø³ÙŠÙ‚ÙˆÙ… Ø¨Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ù…Ø±Ø§Ù‚Ø¨Ø© Ø´Ø§Ù…Ù„ ÙŠØªØ¶Ù…Ù†:"
    echo "  â€¢ Prometheus Ù„Ø¬Ù…Ø¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"
    echo "  â€¢ Grafana Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù„ÙˆØ­Ø§Øª"
    echo "  â€¢ Loki Ù„ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø³Ø¬Ù„Ø§Øª"
    echo "  â€¢ Alertmanager Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª"
    echo "  â€¢ Prometheus exporters Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…Ø®ØªÙ„ÙØ©"
    echo ""
    
    read -p "Ù‡Ù„ ØªØ±ÙŠØ¯ Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©ØŸ (y/N): " -n 1 -r
    echo
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        print_info "ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ«Ø¨ÙŠØª"
        exit 0
    fi
    
    # ØªÙ†ÙÙŠØ° Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ«Ø¨ÙŠØª
    check_requirements
    create_directory_structure
    download_files
    create_docker_compose
    create_prometheus_config
    create_alertmanager_config
    create_loki_config
    setup_grafana
    create_stop_script
    create_backup_script
    create_restore_script
    setup_node_exporter
    start_services
    show_summary
    
    print_success "ØªÙ… Ø§Ù„Ø§Ù†ØªÙ‡Ø§Ø¡ Ù…Ù† Ø§Ù„ØªØ«Ø¨ÙŠØª Ø¨Ù†Ø¬Ø§Ø­! ğŸ‰"
}

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø³ÙƒØ±ÙŠØ¨Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
main "$@"