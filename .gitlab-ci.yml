stages:
  - validate
  - test
  - build
  - security
  - deploy
  - cleanup

variables:
  DOCKER_DRIVER: overlay2
  DOCKER_TLS_CERTDIR: ""
  POSTGRES_DB: saler_test
  POSTGRES_USER: postgres
  POSTGRES_PASSWORD: password
  POSTGRES_HOST_AUTH_METHOD: trust
  REDIS_HOST: redis
  REDIS_PORT: 6379

# Cache configuration
cache:
  key: ${CI_COMMIT_REF_SLUG}
  paths:
    - saler/frontend/node_modules/
    - saler/backend/.venv/
    - .cache/pip/

# Validation stage
validate:frontend:
  stage: validate
  image: node:18-alpine
  script:
    - cd saler/frontend
    - npm ci
    - npm run lint
    - npm run type-check
    - npm run build
  artifacts:
    paths:
      - saler/frontend/dist/
    expire_in: 1 hour
  only:
    - merge_requests
    - main
    - develop

validate:backend:
  stage: validate
  image: python:3.11-alpine
  services:
    - postgres:15-alpine
  before_script:
    - apk add --no-cache postgresql-client
    - cd saler/backend
    - python -m pip install --upgrade pip
    - pip install -r requirements.txt -r requirements-dev.txt
  script:
    - flake8 app/ tests/
    - black --check app/ tests/
    - isort --check-only app/ tests/
    - mypy app/
  artifacts:
    reports:
      junit: saler/backend/flake8-report.xml
  only:
    - merge_requests
    - main
    - develop

# Test stage
test:frontend:
  stage: test
  image: node:18-alpine
  services:
    - name: redis:7-alpine
      alias: redis
  script:
    - cd saler/frontend
    - npm ci
    - npm run test:unit -- --coverage --watchAll=false
    - npm run test:integration
    - npm run test:e2e -- --headless
  coverage: '/Lines\s*:\s*(\d+\.\d+%)/'
  artifacts:
    paths:
      - saler/frontend/coverage/
    reports:
      coverage_report:
        coverage_format: cobertura
        path: saler/frontend/coverage/cobertura-coverage.xml
      junit: saler/frontend/junit.xml
    expire_in: 1 week
  only:
    - merge_requests
    - main
    - develop

test:backend:
  stage: test
  image: python:3.11-alpine
  services:
    - postgres:15-alpine
    - redis:7-alpine
  variables:
    DATABASE_URL: "postgresql://postgres:password@postgres:5432/saler_test"
  before_script:
    - apk add --no-cache postgresql-client redis
    - cd saler/backend
    - python -m pip install --upgrade pip
    - pip install -r requirements.txt -r requirements-dev.txt
    - python -m alembic upgrade head
  script:
    - pytest tests/ -v --cov=app --cov-report=xml --cov-report=html --cov-fail-under=80
  coverage: '/TOTAL\s+\d+\s+\d+\s+(\d+%)/'
  artifacts:
    paths:
      - saler/backend/htmlcov/
      - saler/backend/.coverage
    reports:
      coverage_report:
        coverage_format: cobertura
        path: saler/backend/coverage.xml
      junit: saler/backend/junit.xml
    expire_in: 1 week
  only:
    - merge_requests
    - main
    - develop

test:integration:
  stage: test
  image: python:3.11-alpine
  services:
    - postgres:15-alpine
    - redis:7-alpine
    - elasticsearch:8.11.0
  variables:
    DATABASE_URL: "postgresql://postgres:password@postgres:5432/saler_test"
    ELASTICSEARCH_URL: "http://elasticsearch:9200"
  before_script:
    - apk add --no-cache postgresql-client redis
    - cd saler/backend
    - python -m pip install --upgrade pip
    - pip install -r requirements.txt -r requirements-dev.txt
  script:
    - pytest tests/integration/ -v
  artifacts:
    reports:
      junit: saler/backend/integration-junit.xml
  allow_failure: true
  only:
    - main
    - develop

test:performance:
  stage: test
  image: grafana/k6:0.45.0
  script:
    - cd saler
    - k6 run tests/load/auth-flow.js
    - k6 run tests/load/api-endpoints.js
  artifacts:
    paths:
      - saler/load-test-results.json
    expire_in: 1 week
  only:
    - main
    - schedules

# Build stage
build:frontend:
  stage: build
  image: node:18-alpine
  script:
    - cd saler/frontend
    - npm ci
    - npm run build
    - npm run test:a11y
  artifacts:
    paths:
      - saler/frontend/dist/
    expire_in: 1 hour
  only:
    - main
    - develop
    - tags

build:backend:
  stage: build
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  before_script:
    - cd saler/backend
    - docker build -t $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA .
  script:
    - docker push $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA
    - if [[ "$CI_COMMIT_BRANCH" == "main" ]]; then docker tag $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA $CI_REGISTRY_IMAGE/backend:latest; docker push $CI_REGISTRY_IMAGE/backend:latest; fi
  only:
    - main
    - develop
    - tags

build:docker-compose:
  stage: build
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  script:
    - cd saler
    - docker build -t $CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA ./frontend
    - docker build -t $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA ./backend
    - docker save $CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA | gzip > frontend.tar.gz
    - docker save $CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA | gzip > backend.tar.gz
  artifacts:
    paths:
      - saler/frontend.tar.gz
      - saler/backend.tar.gz
    expire_in: 1 day
  only:
    - main
    - develop

# Security stage
security:frontend:
  stage: security
  image: node:18-alpine
  script:
    - cd saler/frontend
    - npm ci
    - npm audit --audit-level moderate
    - npm run security:check
  artifacts:
    paths:
      - saler/frontend/security-report.json
    expire_in: 1 week
  allow_failure: true
  only:
    - main
    - develop
    - merge_requests

security:backend:
  stage: security
  image: python:3.11-alpine
  before_script:
    - cd saler/backend
    - python -m pip install --upgrade pip
    - pip install -r requirements.txt
    - pip install bandit safety semgrep
  script:
    - bandit -r app/ -f json -o bandit-report.json || true
    - safety check --json --output safety-report.json || true
    - semgrep --config=auto --json --output=semgrep-report.json app/ || true
  artifacts:
    paths:
      - saler/backend/bandit-report.json
      - saler/backend/safety-report.json
      - saler/backend/semgrep-report.json
    expire_in: 1 week
  allow_failure: true
  only:
    - main
    - develop
    - merge_requests

security:container:
  stage: security
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  before_script:
    - apk add --no-cache curl
    - curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh -s -- -b /usr/local/bin
  script:
    - cd saler
    - docker build -t saler-frontend:$CI_COMMIT_SHA ./frontend
    - docker build -t saler-backend:$CI_COMMIT_SHA ./backend
    - trivy image --format json --output frontend-security.json saler-frontend:$CI_COMMIT_SHA || true
    - trivy image --format json --output backend-security.json saler-backend:$CI_COMMIT_SHA || true
  artifacts:
    paths:
      - saler/frontend-security.json
      - saler/backend-security.json
    expire_in: 1 week
  allow_failure: true
  only:
    - main
    - develop

security:secret-scan:
  stage: security
  image: alpine:latest
  before_script:
    - apk add --no-cache git
  script:
    - |
      if command -v gitleaks >/dev/null 2>&1; then
        gitleaks detect --report-format json --report-path gitleaks-report.json || true
      else
        echo "Gitleaks not installed, skipping secret scan"
      fi
  artifacts:
    paths:
      - gitleaks-report.json
    expire_in: 1 week
  allow_failure: true
  only:
    - main
    - develop
    - merge_requests

# Documentation stage
docs:generate:
  stage: build
  image: python:3.11-alpine
  before_script:
    - cd saler/backend
    - python -m pip install --upgrade pip
    - pip install -r requirements.txt
    - pip install sphinx sphinx-rtd-theme
  script:
    - cd saler/backend/docs
    - make html
    - cd ../..
    - python -c "import json; print(json.dumps({'docs_build': 'success'}))" > docs-status.json
  artifacts:
    paths:
      - saler/backend/docs/_build/html/
    expire_in: 1 hour
  only:
    - main
    - develop

# Deploy staging
deploy:staging:
  stage: deploy
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  environment:
    name: staging
    url: https://staging.saler.com
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - cd saler
    - export STAGING=true
    - docker-compose -f docker-compose.staging.yml up -d --build
    - sleep 30
    - curl -f http://localhost:3000/health || exit 1
    - curl -f http://localhost:8000/health || exit 1
  only:
    - develop

# Deploy production
deploy:production:
  stage: deploy
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  environment:
    name: production
    url: https://saler.com
  before_script:
    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
  script:
    - cd saler
    - docker-compose -f docker-compose.prod.yml up -d --build
    - sleep 60
    - curl -f https://saler.com/health || exit 1
  when: manual
  only:
    - main

# Post-deploy testing
test:staging:
  stage: test
  image: node:18-alpine
  services:
    - name: redis:7-alpine
      alias: redis
  script:
    - cd saler
    - npm install -g @playwright/test
    - npx playwright install chromium
    - npx playwright test --project=staging
  environment:
    name: staging
    url: https://staging.saler.com
  only:
    - develop

# Cleanup old artifacts and images
cleanup:
  stage: cleanup
  image: docker:24-dind
  services:
    - docker:24-dind
  variables:
    DOCKER_TLS_CERTDIR: ""
  script:
    - |
      # Cleanup old registry images
      docker rmi $(docker images --filter "before=$CI_REGISTRY_IMAGE/backend:$CI_COMMIT_SHA" -q) || true
      docker rmi $(docker images --filter "before=$CI_REGISTRY_IMAGE/frontend:$CI_COMMIT_SHA" -q) || true
    - |
      # Cleanup old artifacts
      curl -X DELETE --header "PRIVATE-TOKEN: $GITLAB_TOKEN" \
        "$CI_API_V4/projects/$CI_PROJECT_ID/jobs/artifacts?older_than=30d" || true
  when: manual
  only:
    - main

# Notification job
notify:
  stage: cleanup
  image: alpine:latest
  before_script:
    - apk add --no-cache curl
  script:
    - |
      if [ "$CI_JOB_STATUS" = "success" ]; then
        MESSAGE="✅ CI/CD pipeline completed successfully for $CI_COMMIT_REF_NAME"
      else
        MESSAGE="❌ CI/CD pipeline failed for $CI_COMMIT_REF_NAME"
      fi
    - |
      if [ -n "$SLACK_WEBHOOK_URL" ]; then
        curl -X POST -H 'Content-type: application/json' \
          --data "{\"text\":\"$MESSAGE\\nBranch: $CI_COMMIT_REF_NAME\\nCommit: $CI_COMMIT_SHA\\nPipeline: $CI_PIPELINE_URL\"}" \
          $SLACK_WEBHOOK_URL || true
      fi
  when: always
  only:
    - main
    - develop

# Parallel test execution
.parallel_test_template: &parallel_test_template
  parallel:
    matrix:
      - TEST_SUITE: ["auth", "api", "database", "integrations"]

test:parallel:
  <<: *parallel_test_template
  stage: test
  script:
    - pytest tests/$TEST_SUITE/ -v

# Template for manual jobs
.template_manual:
  script:
    - echo "Manual job execution"
  when: manual
  only:
    - main

# Rollback job
rollback:
  extends: .template_manual
  stage: deploy
  script:
    - cd saler
    - docker-compose -f docker-compose.prod.yml rollback
  environment:
    name: production
    url: https://saler.com
  only:
    - main

# Database migration job
migrate:production:
  extends: .template_manual
  stage: deploy
  image: python:3.11-alpine
  script:
    - cd saler/backend
    - python -m alembic upgrade head
  environment:
    name: production
  only:
    - main
